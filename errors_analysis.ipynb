{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error study of the 2 bit quantized dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from util.build_dino import build_dino_model\n",
    "from gptq.modelutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_checkpoint!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "root = \"./\"\n",
    "\n",
    "model = build_dino_model(root, backbone=\"swin-L\")\n",
    "layers = find_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(name: str):\n",
    "    s = \"\"\n",
    "    if name.startswith(\"0.\"):\n",
    "        s = f\"Backbone_{name[4:]}\"\n",
    "    elif name.startswith(\"1.\"):\n",
    "        s = f\"Input_projection_{name[2:]}\"\n",
    "    elif name.startswith(\"14\"):\n",
    "        s = \"Label_classifier\"\n",
    "    elif name.startswith(\"15\"):\n",
    "        s = f\"Bbox_predictor_{name[3:]}\"\n",
    "    elif name.startswith(\"16\"):\n",
    "        s = \"Query_selction_enc_output\"\n",
    "    elif name.startswith(\"17\"):\n",
    "        s = \"Query_selction_enc_out_class_embed\"\n",
    "    elif name.startswith(\"18\"):\n",
    "        s = f\"Query_selction_enc_out_bbox_embed_{name[-8:]}\"\n",
    "    elif int(name.split(\".\", 1)[0]) >= 8:\n",
    "        s = f\"Decoder_{int(name.split('.', 1)[0]) - 8}_{name.split('.', 1)[1]}\"\n",
    "    else:\n",
    "        s = f\"Encoder_{int(name[0]) - 2}_{name[2:]}\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding layer number of parameters\n",
    "layers = model.transformer.encoder.layers + model.transformer.decoder.layers\n",
    "layers.insert(0, model.input_proj)\n",
    "layers.insert(0, model.backbone)\n",
    "layers = layers.append(model.class_embed[0])\n",
    "layers = layers.append(model.bbox_embed[0])\n",
    "layers = layers.append(model.transformer.enc_output)\n",
    "layers = layers.append(model.transformer.enc_out_class_embed)\n",
    "layers = layers.append(model.transformer.enc_out_bbox_embed)\n",
    "layers = find_layers(layers)\n",
    "\n",
    "layers = {get_name(k):v for k,v in layers.items()}\n",
    "number_of_parameters = {k:int(v.weight.numel()) for k,v in layers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part(s):\n",
    "  if s.startswith(\"Backbone\") or  s.startswith(\"Input_projection\"):\n",
    "    return \"backbone\"\n",
    "  elif s.startswith(\"Encoder\") or s.startswith(\"Decoder\"):\n",
    "    return \"transformer\"\n",
    "  elif s.startswith(\"Query_selction\"):\n",
    "    return \"query_selection\"\n",
    "  elif s.startswith(\"Bbox_predictor\") or s.startswith(\"Label_classifier\"):\n",
    "    return \"output_head\"\n",
    "\n",
    "def get_sub_part(s):\n",
    "  if s.startswith(\"Backbone\"):\n",
    "    return \"backbone\"\n",
    "  elif s.startswith(\"Input_projection\"):\n",
    "    return \"input_projection\"\n",
    "  elif s.startswith(\"Encoder\"):\n",
    "    return \"encoder\"\n",
    "  elif s.startswith(\"Decoder\"):\n",
    "    return \"decoder\"\n",
    "  elif s.startswith(\"Query_selction\"):\n",
    "    return \"query_selection\"\n",
    "  elif s.startswith(\"Bbox_predictor\"):\n",
    "    return \"bbox_predictor\"\n",
    "  elif s.startswith(\"Label_classifier\"):\n",
    "    return \"label_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>part</th>\n",
       "      <th>sub_part</th>\n",
       "      <th>number_of_parameters</th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backbone_patch_embed.proj</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>9216</td>\n",
       "      <td>40777.55</td>\n",
       "      <td>76.48</td>\n",
       "      <td>4.424648</td>\n",
       "      <td>0.008299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Backbone_layers.0.blocks.0.attn.qkv</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>110592</td>\n",
       "      <td>242.70</td>\n",
       "      <td>185.70</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Backbone_layers.0.blocks.0.attn.proj</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>36864</td>\n",
       "      <td>105.53</td>\n",
       "      <td>134.97</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.003661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Backbone_layers.0.blocks.0.mlp.fc1</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>147456</td>\n",
       "      <td>846797.75</td>\n",
       "      <td>155.21</td>\n",
       "      <td>5.742715</td>\n",
       "      <td>0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Backbone_layers.0.blocks.0.mlp.fc2</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>147456</td>\n",
       "      <td>267143.69</td>\n",
       "      <td>328.19</td>\n",
       "      <td>1.811684</td>\n",
       "      <td>0.002226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Query_selction_enc_output</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>65536</td>\n",
       "      <td>74335.26</td>\n",
       "      <td>63.56</td>\n",
       "      <td>1.134266</td>\n",
       "      <td>0.000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Query_selction_enc_out_class_embed</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>23296</td>\n",
       "      <td>32592.27</td>\n",
       "      <td>767.29</td>\n",
       "      <td>1.399050</td>\n",
       "      <td>0.032937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Query_selction_enc_out_bbox_embed_layers.0</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>65536</td>\n",
       "      <td>50807.65</td>\n",
       "      <td>229.69</td>\n",
       "      <td>0.775263</td>\n",
       "      <td>0.003505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Query_selction_enc_out_bbox_embed_layers.1</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>65536</td>\n",
       "      <td>41114.84</td>\n",
       "      <td>602.21</td>\n",
       "      <td>0.627363</td>\n",
       "      <td>0.009189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Query_selction_enc_out_bbox_embed_layers.2</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>1024</td>\n",
       "      <td>13317.92</td>\n",
       "      <td>92.92</td>\n",
       "      <td>13.005785</td>\n",
       "      <td>0.090743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          layer             part  \\\n",
       "0                     Backbone_patch_embed.proj         backbone   \n",
       "1           Backbone_layers.0.blocks.0.attn.qkv         backbone   \n",
       "2          Backbone_layers.0.blocks.0.attn.proj         backbone   \n",
       "3            Backbone_layers.0.blocks.0.mlp.fc1         backbone   \n",
       "4            Backbone_layers.0.blocks.0.mlp.fc2         backbone   \n",
       "..                                          ...              ...   \n",
       "204                   Query_selction_enc_output  query_selection   \n",
       "205          Query_selction_enc_out_class_embed  query_selection   \n",
       "206  Query_selction_enc_out_bbox_embed_layers.0  query_selection   \n",
       "207  Query_selction_enc_out_bbox_embed_layers.1  query_selection   \n",
       "208  Query_selction_enc_out_bbox_embed_layers.2  query_selection   \n",
       "\n",
       "            sub_part  number_of_parameters  error_gptq  error_ldlq  \\\n",
       "0           backbone                  9216    40777.55       76.48   \n",
       "1           backbone                110592      242.70      185.70   \n",
       "2           backbone                 36864      105.53      134.97   \n",
       "3           backbone                147456   846797.75      155.21   \n",
       "4           backbone                147456   267143.69      328.19   \n",
       "..               ...                   ...         ...         ...   \n",
       "204  query_selection                 65536    74335.26       63.56   \n",
       "205  query_selection                 23296    32592.27      767.29   \n",
       "206  query_selection                 65536    50807.65      229.69   \n",
       "207  query_selection                 65536    41114.84      602.21   \n",
       "208  query_selection                  1024    13317.92       92.92   \n",
       "\n",
       "     normalized_error_gptq  normalized_error_ldlq  \n",
       "0                 4.424648               0.008299  \n",
       "1                 0.002195               0.001679  \n",
       "2                 0.002863               0.003661  \n",
       "3                 5.742715               0.001053  \n",
       "4                 1.811684               0.002226  \n",
       "..                     ...                    ...  \n",
       "204               1.134266               0.000970  \n",
       "205               1.399050               0.032937  \n",
       "206               0.775263               0.003505  \n",
       "207               0.627363               0.009189  \n",
       "208              13.005785               0.090743  \n",
       "\n",
       "[209 rows x 8 columns]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino_swin_ldlq = pd.read_csv('errors/dino-swin-L_ldlq_IP_transformer_backbone_output_head_query_selection_100samples_2bits.csv', names=[\"layer\", \"error_ldlq\"], header=0)\n",
    "dino_swin_gptq = pd.read_csv('errors/dino-swin-L_gptq_transformer_backbone_output_head_query_selection_100samples_2bits.csv', names=[\"layer\", \"error_gptq\"], header=0)\n",
    "dino_swin = pd.merge(dino_swin_gptq, dino_swin_ldlq, on=\"layer\")\n",
    "dino_swin[\"part\"] = dino_swin.layer.apply(get_part)\n",
    "dino_swin[\"sub_part\"] = dino_swin.layer.apply(get_sub_part)\n",
    "dino_swin[\"number_of_parameters\"] = dino_swin.layer.apply(number_of_parameters.get)\n",
    "dino_swin[\"normalized_error_gptq\"] = dino_swin.error_gptq / dino_swin.number_of_parameters\n",
    "dino_swin[\"normalized_error_ldlq\"] = dino_swin.error_ldlq / dino_swin.number_of_parameters\n",
    "dino_swin[\"error_gptq\"] = dino_swin.error_gptq.round(2)\n",
    "dino_swin[\"error_ldlq\"] = dino_swin.error_ldlq.round(2)\n",
    "dino_swin = dino_swin[[\"layer\", \"part\", \"sub_part\", \"number_of_parameters\", \"error_gptq\", \"error_ldlq\", \"normalized_error_gptq\", \"normalized_error_ldlq\"]]\n",
    "dino_swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th>gptq_AP</th>\n",
       "      <th>ldlq_AP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">number_of_parameters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>backbone</th>\n",
       "      <td>4656385.05</td>\n",
       "      <td>1703.64</td>\n",
       "      <td>2.226951</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>21.6</td>\n",
       "      <td>48.4</td>\n",
       "      <td>1912290</td>\n",
       "      <td>198878208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transformer</th>\n",
       "      <td>176637.13</td>\n",
       "      <td>583.21</td>\n",
       "      <td>1.084220</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>53.0</td>\n",
       "      <td>51.2</td>\n",
       "      <td>176128</td>\n",
       "      <td>16908288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_selection</th>\n",
       "      <td>42433.59</td>\n",
       "      <td>351.13</td>\n",
       "      <td>3.388345</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>52.4</td>\n",
       "      <td>57.1</td>\n",
       "      <td>44185</td>\n",
       "      <td>220928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output_head</th>\n",
       "      <td>2369.04</td>\n",
       "      <td>211.56</td>\n",
       "      <td>0.061067</td>\n",
       "      <td>0.023208</td>\n",
       "      <td>54.4</td>\n",
       "      <td>39.3</td>\n",
       "      <td>38848</td>\n",
       "      <td>155392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 error_gptq error_ldlq normalized_error_gptq  \\\n",
       "                       mean       mean                  mean   \n",
       "part                                                           \n",
       "backbone         4656385.05    1703.64              2.226951   \n",
       "transformer       176637.13     583.21              1.084220   \n",
       "query_selection    42433.59     351.13              3.388345   \n",
       "output_head         2369.04     211.56              0.061067   \n",
       "\n",
       "                normalized_error_ldlq gptq_AP ldlq_AP number_of_parameters  \\\n",
       "                                 mean                                 mean   \n",
       "part                                                                         \n",
       "backbone                     0.001294    21.6    48.4              1912290   \n",
       "transformer                  0.005765    53.0    51.2               176128   \n",
       "query_selection              0.027469    52.4    57.1                44185   \n",
       "output_head                  0.023208    54.4    39.3                38848   \n",
       "\n",
       "                            \n",
       "                       sum  \n",
       "part                        \n",
       "backbone         198878208  \n",
       "transformer       16908288  \n",
       "query_selection     220928  \n",
       "output_head         155392  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_error = dino_swin[[\"part\", \"error_gptq\", \"error_ldlq\", \"normalized_error_gptq\", \"normalized_error_ldlq\", \"number_of_parameters\"]].groupby(\"part\").agg({\"error_gptq\": \"mean\", \"error_ldlq\": \"mean\", \"normalized_error_gptq\": \"mean\", \"normalized_error_ldlq\": \"mean\", \"number_of_parameters\": [\"mean\", \"sum\"]})\n",
    "mean_error[\"error_gptq\"] = mean_error[\"error_gptq\"].round(2)\n",
    "mean_error[\"error_ldlq\"] = mean_error[\"error_ldlq\"].round(2)\n",
    "mean_error[\"number_of_parameters\"] = mean_error[\"number_of_parameters\"].astype(int)\n",
    "mean_error[\"gptq_AP\"] = [21.6, 54.4, 52.4, 53.0]\n",
    "mean_error[\"ldlq_AP\"] = [48.4, 39.3, 57.1, 51.2]\n",
    "mean_error[[(\"error_gptq\", \"mean\"), (\"error_ldlq\", \"mean\"), (\"normalized_error_gptq\", \"mean\"), (\"normalized_error_ldlq\", \"mean\"), (\"gptq_AP\", \"\"), (\"ldlq_AP\", \"\"), (\"number_of_parameters\", \"mean\"), (\"number_of_parameters\", \"sum\")]].loc[[\"backbone\", \"transformer\", \"query_selection\", \"output_head\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highest error layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>part</th>\n",
       "      <th>sub_part</th>\n",
       "      <th>number_of_parameters</th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Backbone_layers.2.blocks.17.mlp.fc1</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>2359296</td>\n",
       "      <td>1.129683e+08</td>\n",
       "      <td>3656.98</td>\n",
       "      <td>47.882222</td>\n",
       "      <td>0.001550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Backbone_layers.2.blocks.16.mlp.fc1</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>2359296</td>\n",
       "      <td>1.082036e+08</td>\n",
       "      <td>3023.03</td>\n",
       "      <td>45.862664</td>\n",
       "      <td>0.001281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Backbone_layers.2.blocks.15.mlp.fc1</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>2359296</td>\n",
       "      <td>8.817858e+07</td>\n",
       "      <td>2588.64</td>\n",
       "      <td>37.374953</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Backbone_layers.2.blocks.14.mlp.fc1</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>2359296</td>\n",
       "      <td>5.778317e+07</td>\n",
       "      <td>2189.38</td>\n",
       "      <td>24.491699</td>\n",
       "      <td>0.000928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Backbone_layers.0.blocks.1.mlp.fc1</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>147456</td>\n",
       "      <td>2.205139e+06</td>\n",
       "      <td>215.56</td>\n",
       "      <td>14.954558</td>\n",
       "      <td>0.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Backbone_layers.2.blocks.13.mlp.fc1</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>2359296</td>\n",
       "      <td>3.406924e+07</td>\n",
       "      <td>1848.09</td>\n",
       "      <td>14.440426</td>\n",
       "      <td>0.000783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Query_selction_enc_out_bbox_embed_layers.2</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>1024</td>\n",
       "      <td>1.331792e+04</td>\n",
       "      <td>92.92</td>\n",
       "      <td>13.005785</td>\n",
       "      <td>0.090743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Encoder_0_self_attn.value_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>4.022420e+05</td>\n",
       "      <td>270.40</td>\n",
       "      <td>6.137725</td>\n",
       "      <td>0.004126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Backbone_layers.2.blocks.12.mlp.fc1</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>2359296</td>\n",
       "      <td>1.434951e+07</td>\n",
       "      <td>1323.74</td>\n",
       "      <td>6.082115</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Backbone_layers.0.blocks.0.mlp.fc1</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>147456</td>\n",
       "      <td>8.467978e+05</td>\n",
       "      <td>155.21</td>\n",
       "      <td>5.742715</td>\n",
       "      <td>0.001053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          layer             part  \\\n",
       "89          Backbone_layers.2.blocks.17.mlp.fc1         backbone   \n",
       "85          Backbone_layers.2.blocks.16.mlp.fc1         backbone   \n",
       "81          Backbone_layers.2.blocks.15.mlp.fc1         backbone   \n",
       "77          Backbone_layers.2.blocks.14.mlp.fc1         backbone   \n",
       "7            Backbone_layers.0.blocks.1.mlp.fc1         backbone   \n",
       "73          Backbone_layers.2.blocks.13.mlp.fc1         backbone   \n",
       "208  Query_selction_enc_out_bbox_embed_layers.2  query_selection   \n",
       "106              Encoder_0_self_attn.value_proj      transformer   \n",
       "69          Backbone_layers.2.blocks.12.mlp.fc1         backbone   \n",
       "3            Backbone_layers.0.blocks.0.mlp.fc1         backbone   \n",
       "\n",
       "            sub_part  number_of_parameters    error_gptq  error_ldlq  \\\n",
       "89          backbone               2359296  1.129683e+08     3656.98   \n",
       "85          backbone               2359296  1.082036e+08     3023.03   \n",
       "81          backbone               2359296  8.817858e+07     2588.64   \n",
       "77          backbone               2359296  5.778317e+07     2189.38   \n",
       "7           backbone                147456  2.205139e+06      215.56   \n",
       "73          backbone               2359296  3.406924e+07     1848.09   \n",
       "208  query_selection                  1024  1.331792e+04       92.92   \n",
       "106          encoder                 65536  4.022420e+05      270.40   \n",
       "69          backbone               2359296  1.434951e+07     1323.74   \n",
       "3           backbone                147456  8.467978e+05      155.21   \n",
       "\n",
       "     normalized_error_gptq  normalized_error_ldlq  \n",
       "89               47.882222               0.001550  \n",
       "85               45.862664               0.001281  \n",
       "81               37.374953               0.001097  \n",
       "77               24.491699               0.000928  \n",
       "7                14.954558               0.001462  \n",
       "73               14.440426               0.000783  \n",
       "208              13.005785               0.090743  \n",
       "106               6.137725               0.004126  \n",
       "69                6.082115               0.000561  \n",
       "3                 5.742715               0.001053  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino_swin.sort_values(by=\"normalized_error_gptq\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>part</th>\n",
       "      <th>sub_part</th>\n",
       "      <th>number_of_parameters</th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Query_selction_enc_out_bbox_embed_layers.2</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>1024</td>\n",
       "      <td>13317.92</td>\n",
       "      <td>92.92</td>\n",
       "      <td>13.005785</td>\n",
       "      <td>0.090743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Bbox_predictor_layers.2</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>1024</td>\n",
       "      <td>42.34</td>\n",
       "      <td>75.18</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.073417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Decoder_0_cross_attn.attention_weights</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>32768</td>\n",
       "      <td>672.99</td>\n",
       "      <td>1416.74</td>\n",
       "      <td>0.020538</td>\n",
       "      <td>0.043236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Decoder_5_self_attn.k_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>8985.45</td>\n",
       "      <td>2265.23</td>\n",
       "      <td>0.137107</td>\n",
       "      <td>0.034565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Query_selction_enc_out_class_embed</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>query_selection</td>\n",
       "      <td>23296</td>\n",
       "      <td>32592.27</td>\n",
       "      <td>767.29</td>\n",
       "      <td>1.399050</td>\n",
       "      <td>0.032937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Decoder_5_self_attn.q_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>14565.74</td>\n",
       "      <td>1225.72</td>\n",
       "      <td>0.222256</td>\n",
       "      <td>0.018703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Decoder_1_cross_attn.attention_weights</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>32768</td>\n",
       "      <td>2682.10</td>\n",
       "      <td>554.68</td>\n",
       "      <td>0.081851</td>\n",
       "      <td>0.016928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Decoder_5_cross_attn.sampling_offsets</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>6699.32</td>\n",
       "      <td>1022.07</td>\n",
       "      <td>0.102224</td>\n",
       "      <td>0.015596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Encoder_0_self_attn.sampling_offsets</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>141620.66</td>\n",
       "      <td>1009.97</td>\n",
       "      <td>2.160960</td>\n",
       "      <td>0.015411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Encoder_2_self_attn.attention_weights</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>32768</td>\n",
       "      <td>69700.28</td>\n",
       "      <td>487.87</td>\n",
       "      <td>2.127084</td>\n",
       "      <td>0.014888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          layer             part  \\\n",
       "208  Query_selction_enc_out_bbox_embed_layers.2  query_selection   \n",
       "203                     Bbox_predictor_layers.2      output_head   \n",
       "141      Decoder_0_cross_attn.attention_weights      transformer   \n",
       "194                  Decoder_5_self_attn.k_proj      transformer   \n",
       "205          Query_selction_enc_out_class_embed  query_selection   \n",
       "196                  Decoder_5_self_attn.q_proj      transformer   \n",
       "151      Decoder_1_cross_attn.attention_weights      transformer   \n",
       "190       Decoder_5_cross_attn.sampling_offsets      transformer   \n",
       "104        Encoder_0_self_attn.sampling_offsets      transformer   \n",
       "117       Encoder_2_self_attn.attention_weights      transformer   \n",
       "\n",
       "            sub_part  number_of_parameters  error_gptq  error_ldlq  \\\n",
       "208  query_selection                  1024    13317.92       92.92   \n",
       "203   bbox_predictor                  1024       42.34       75.18   \n",
       "141          decoder                 32768      672.99     1416.74   \n",
       "194          decoder                 65536     8985.45     2265.23   \n",
       "205  query_selection                 23296    32592.27      767.29   \n",
       "196          decoder                 65536    14565.74     1225.72   \n",
       "151          decoder                 32768     2682.10      554.68   \n",
       "190          decoder                 65536     6699.32     1022.07   \n",
       "104          encoder                 65536   141620.66     1009.97   \n",
       "117          encoder                 32768    69700.28      487.87   \n",
       "\n",
       "     normalized_error_gptq  normalized_error_ldlq  \n",
       "208              13.005785               0.090743  \n",
       "203               0.041350               0.073417  \n",
       "141               0.020538               0.043236  \n",
       "194               0.137107               0.034565  \n",
       "205               1.399050               0.032937  \n",
       "196               0.222256               0.018703  \n",
       "151               0.081851               0.016928  \n",
       "190               0.102224               0.015596  \n",
       "104               2.160960               0.015411  \n",
       "117               2.127084               0.014888  "
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino_swin.sort_values(by=\"normalized_error_ldlq\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean error by model's parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th>gptq_AP</th>\n",
       "      <th>ldlq_AP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">number_of_parameters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>backbone</th>\n",
       "      <td>4656385.05</td>\n",
       "      <td>1703.64</td>\n",
       "      <td>2.226951</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>21.6</td>\n",
       "      <td>48.4</td>\n",
       "      <td>1912290</td>\n",
       "      <td>198878208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transformer</th>\n",
       "      <td>176637.13</td>\n",
       "      <td>583.21</td>\n",
       "      <td>1.084220</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>53.0</td>\n",
       "      <td>51.2</td>\n",
       "      <td>176128</td>\n",
       "      <td>16908288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_selection</th>\n",
       "      <td>42433.59</td>\n",
       "      <td>351.13</td>\n",
       "      <td>3.388345</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>52.4</td>\n",
       "      <td>57.1</td>\n",
       "      <td>44185</td>\n",
       "      <td>220928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output_head</th>\n",
       "      <td>2369.04</td>\n",
       "      <td>211.56</td>\n",
       "      <td>0.061067</td>\n",
       "      <td>0.023208</td>\n",
       "      <td>54.4</td>\n",
       "      <td>39.3</td>\n",
       "      <td>38848</td>\n",
       "      <td>155392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 error_gptq error_ldlq normalized_error_gptq  \\\n",
       "                       mean       mean                  mean   \n",
       "part                                                           \n",
       "backbone         4656385.05    1703.64              2.226951   \n",
       "transformer       176637.13     583.21              1.084220   \n",
       "query_selection    42433.59     351.13              3.388345   \n",
       "output_head         2369.04     211.56              0.061067   \n",
       "\n",
       "                normalized_error_ldlq gptq_AP ldlq_AP number_of_parameters  \\\n",
       "                                 mean                                 mean   \n",
       "part                                                                         \n",
       "backbone                     0.001294    21.6    48.4              1912290   \n",
       "transformer                  0.005765    53.0    51.2               176128   \n",
       "query_selection              0.027469    52.4    57.1                44185   \n",
       "output_head                  0.023208    54.4    39.3                38848   \n",
       "\n",
       "                            \n",
       "                       sum  \n",
       "part                        \n",
       "backbone         198878208  \n",
       "transformer       16908288  \n",
       "query_selection     220928  \n",
       "output_head         155392  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_error = dino_swin[[\"part\", \"error_gptq\", \"error_ldlq\", \"normalized_error_gptq\", \"normalized_error_ldlq\", \"number_of_parameters\"]].groupby(\"part\").agg({\"error_gptq\": \"mean\", \"error_ldlq\": \"mean\", \"normalized_error_gptq\": \"mean\", \"normalized_error_ldlq\": \"mean\", \"number_of_parameters\": [\"mean\", \"sum\"]})\n",
    "mean_error[\"error_gptq\"] = mean_error[\"error_gptq\"].round(2)\n",
    "mean_error[\"error_ldlq\"] = mean_error[\"error_ldlq\"].round(2)\n",
    "mean_error[\"number_of_parameters\"] = mean_error[\"number_of_parameters\"].astype(int)\n",
    "mean_error[\"gptq_AP\"] = [21.6, 54.4, 52.4, 53.0]\n",
    "mean_error[\"ldlq_AP\"] = [48.4, 39.3, 57.1, 51.2]\n",
    "mean_error[[(\"error_gptq\", \"mean\"), (\"error_ldlq\", \"mean\"), (\"normalized_error_gptq\", \"mean\"), (\"normalized_error_ldlq\", \"mean\"), (\"gptq_AP\", \"\"), (\"ldlq_AP\", \"\"), (\"number_of_parameters\", \"mean\"), (\"number_of_parameters\", \"sum\")]].loc[[\"backbone\", \"transformer\", \"query_selection\", \"output_head\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th colspan=\"2\" halign=\"left\">number_of_parameters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_part</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>backbone</th>\n",
       "      <td>4832405.39</td>\n",
       "      <td>1687.71</td>\n",
       "      <td>2.262509</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>1946511</td>\n",
       "      <td>194651136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_projection</th>\n",
       "      <td>255876.55</td>\n",
       "      <td>2102.04</td>\n",
       "      <td>1.338024</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>1056768</td>\n",
       "      <td>4227072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder</th>\n",
       "      <td>451572.35</td>\n",
       "      <td>631.89</td>\n",
       "      <td>2.586904</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>212992</td>\n",
       "      <td>7667712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder</th>\n",
       "      <td>11676.00</td>\n",
       "      <td>554.00</td>\n",
       "      <td>0.182610</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>154009</td>\n",
       "      <td>9240576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_selection</th>\n",
       "      <td>42433.59</td>\n",
       "      <td>351.13</td>\n",
       "      <td>3.388345</td>\n",
       "      <td>0.027469</td>\n",
       "      <td>44185</td>\n",
       "      <td>220928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbox_predictor</th>\n",
       "      <td>2448.25</td>\n",
       "      <td>189.92</td>\n",
       "      <td>0.050925</td>\n",
       "      <td>0.026988</td>\n",
       "      <td>44032</td>\n",
       "      <td>132096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_classifier</th>\n",
       "      <td>2131.40</td>\n",
       "      <td>276.49</td>\n",
       "      <td>0.091492</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>23296</td>\n",
       "      <td>23296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  error_gptq error_ldlq normalized_error_gptq  \\\n",
       "                        mean       mean                  mean   \n",
       "sub_part                                                        \n",
       "backbone          4832405.39    1687.71              2.262509   \n",
       "input_projection   255876.55    2102.04              1.338024   \n",
       "encoder            451572.35     631.89              2.586904   \n",
       "decoder             11676.00     554.00              0.182610   \n",
       "query_selection     42433.59     351.13              3.388345   \n",
       "bbox_predictor       2448.25     189.92              0.050925   \n",
       "label_classifier     2131.40     276.49              0.091492   \n",
       "\n",
       "                 normalized_error_ldlq number_of_parameters             \n",
       "                                  mean                 mean        sum  \n",
       "sub_part                                                                \n",
       "backbone                      0.001307              1946511  194651136  \n",
       "input_projection              0.000972              1056768    4227072  \n",
       "encoder                       0.005641               212992    7667712  \n",
       "decoder                       0.005839               154009    9240576  \n",
       "query_selection               0.027469                44185     220928  \n",
       "bbox_predictor                0.026988                44032     132096  \n",
       "label_classifier              0.011869                23296      23296  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_error = dino_swin[[\"sub_part\", \"error_gptq\", \"error_ldlq\", \"normalized_error_gptq\", \"normalized_error_ldlq\", \"number_of_parameters\"]].groupby(\"sub_part\").agg({\"error_gptq\": \"mean\", \"error_ldlq\": \"mean\", \"normalized_error_gptq\": \"mean\", \"normalized_error_ldlq\": \"mean\", \"number_of_parameters\": [\"mean\", \"sum\"]})\n",
    "mean_error[\"error_gptq\"] = mean_error[\"error_gptq\"].round(2)\n",
    "mean_error[\"error_ldlq\"] = mean_error[\"error_ldlq\"].round(2)\n",
    "mean_error[\"number_of_parameters\"] = mean_error[\"number_of_parameters\"].astype(int)\n",
    "mean_error.loc[[\"backbone\", \"input_projection\", \"encoder\", \"decoder\", \"query_selection\", \"bbox_predictor\", \"label_classifier\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = dino_swin[dino_swin.part == \"transformer\"].copy()\n",
    "trans[\"trans_part\"] = trans.layer.str.split('_', n=2).str[-1]\n",
    "trans[\"nb_layer\"] = trans.layer.str.split('_', n=3).str[1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_part</th>\n",
       "      <th>nb_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">encoder</th>\n",
       "      <th>0</th>\n",
       "      <td>599228.280000</td>\n",
       "      <td>719.701667</td>\n",
       "      <td>3.062971</td>\n",
       "      <td>0.006407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540224.816667</td>\n",
       "      <td>641.108333</td>\n",
       "      <td>2.877755</td>\n",
       "      <td>0.005941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>438957.775000</td>\n",
       "      <td>667.448333</td>\n",
       "      <td>2.475449</td>\n",
       "      <td>0.005994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>437630.778333</td>\n",
       "      <td>601.911667</td>\n",
       "      <td>2.219882</td>\n",
       "      <td>0.004731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>414707.791667</td>\n",
       "      <td>613.710000</td>\n",
       "      <td>2.783273</td>\n",
       "      <td>0.005531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>278684.673333</td>\n",
       "      <td>547.483333</td>\n",
       "      <td>2.102096</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">decoder</th>\n",
       "      <th>0</th>\n",
       "      <td>13176.294000</td>\n",
       "      <td>737.988000</td>\n",
       "      <td>0.201975</td>\n",
       "      <td>0.009778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11499.625000</td>\n",
       "      <td>427.407000</td>\n",
       "      <td>0.179450</td>\n",
       "      <td>0.004458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11667.025000</td>\n",
       "      <td>319.919000</td>\n",
       "      <td>0.183686</td>\n",
       "      <td>0.003265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11852.527000</td>\n",
       "      <td>405.243000</td>\n",
       "      <td>0.186188</td>\n",
       "      <td>0.003787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10624.167000</td>\n",
       "      <td>511.153000</td>\n",
       "      <td>0.167217</td>\n",
       "      <td>0.004231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11236.361000</td>\n",
       "      <td>922.261000</td>\n",
       "      <td>0.177143</td>\n",
       "      <td>0.009515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      error_gptq  error_ldlq  normalized_error_gptq  \\\n",
       "sub_part nb_layer                                                     \n",
       "encoder  0         599228.280000  719.701667               3.062971   \n",
       "         1         540224.816667  641.108333               2.877755   \n",
       "         2         438957.775000  667.448333               2.475449   \n",
       "         3         437630.778333  601.911667               2.219882   \n",
       "         4         414707.791667  613.710000               2.783273   \n",
       "         5         278684.673333  547.483333               2.102096   \n",
       "decoder  0          13176.294000  737.988000               0.201975   \n",
       "         1          11499.625000  427.407000               0.179450   \n",
       "         2          11667.025000  319.919000               0.183686   \n",
       "         3          11852.527000  405.243000               0.186188   \n",
       "         4          10624.167000  511.153000               0.167217   \n",
       "         5          11236.361000  922.261000               0.177143   \n",
       "\n",
       "                   normalized_error_ldlq  \n",
       "sub_part nb_layer                         \n",
       "encoder  0                      0.006407  \n",
       "         1                      0.005941  \n",
       "         2                      0.005994  \n",
       "         3                      0.004731  \n",
       "         4                      0.005531  \n",
       "         5                      0.005242  \n",
       "decoder  0                      0.009778  \n",
       "         1                      0.004458  \n",
       "         2                      0.003265  \n",
       "         3                      0.003787  \n",
       "         4                      0.004231  \n",
       "         5                      0.009515  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[[\"sub_part\", \"nb_layer\", \"error_gptq\", \"error_ldlq\", \"normalized_error_gptq\", \"normalized_error_ldlq\"]].groupby([\"sub_part\", \"nb_layer\"]).mean().loc[[\"encoder\", \"decoder\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_part</th>\n",
       "      <th>trans_part</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">encoder</th>\n",
       "      <th>self_attn.attention_weights</th>\n",
       "      <td>7.167297e+04</td>\n",
       "      <td>381.266667</td>\n",
       "      <td>2.187285</td>\n",
       "      <td>0.011635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.output_proj</th>\n",
       "      <td>2.026401e+05</td>\n",
       "      <td>218.688333</td>\n",
       "      <td>3.092043</td>\n",
       "      <td>0.003337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.sampling_offsets</th>\n",
       "      <td>1.198736e+05</td>\n",
       "      <td>746.206667</td>\n",
       "      <td>1.829126</td>\n",
       "      <td>0.011386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.value_proj</th>\n",
       "      <td>2.993676e+05</td>\n",
       "      <td>211.565000</td>\n",
       "      <td>4.567987</td>\n",
       "      <td>0.003228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear1</th>\n",
       "      <td>1.907164e+06</td>\n",
       "      <td>755.916667</td>\n",
       "      <td>3.637627</td>\n",
       "      <td>0.001442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear2</th>\n",
       "      <td>1.087157e+05</td>\n",
       "      <td>1477.720000</td>\n",
       "      <td>0.207359</td>\n",
       "      <td>0.002819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">decoder</th>\n",
       "      <th>cross_attn.attention_weights</th>\n",
       "      <td>2.978128e+03</td>\n",
       "      <td>564.711667</td>\n",
       "      <td>0.090885</td>\n",
       "      <td>0.017234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_attn.output_proj</th>\n",
       "      <td>5.137910e+03</td>\n",
       "      <td>241.780000</td>\n",
       "      <td>0.078398</td>\n",
       "      <td>0.003689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_attn.sampling_offsets</th>\n",
       "      <td>4.469888e+03</td>\n",
       "      <td>582.711667</td>\n",
       "      <td>0.068205</td>\n",
       "      <td>0.008891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_attn.value_proj</th>\n",
       "      <td>8.270184e+04</td>\n",
       "      <td>55.356667</td>\n",
       "      <td>1.261930</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.k_proj</th>\n",
       "      <td>7.563838e+03</td>\n",
       "      <td>668.545000</td>\n",
       "      <td>0.115415</td>\n",
       "      <td>0.010201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.out_proj</th>\n",
       "      <td>1.646522e+03</td>\n",
       "      <td>265.313333</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>0.004048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.q_proj</th>\n",
       "      <td>8.507283e+03</td>\n",
       "      <td>461.458333</td>\n",
       "      <td>0.129811</td>\n",
       "      <td>0.007041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.v_proj</th>\n",
       "      <td>3.682638e+03</td>\n",
       "      <td>96.638333</td>\n",
       "      <td>0.056193</td>\n",
       "      <td>0.001475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear1</th>\n",
       "      <td>6.408833e+01</td>\n",
       "      <td>489.408333</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear2</th>\n",
       "      <td>7.866667e+00</td>\n",
       "      <td>2114.028333</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         error_gptq   error_ldlq  \\\n",
       "sub_part trans_part                                                \n",
       "encoder  self_attn.attention_weights   7.167297e+04   381.266667   \n",
       "         self_attn.output_proj         2.026401e+05   218.688333   \n",
       "         self_attn.sampling_offsets    1.198736e+05   746.206667   \n",
       "         self_attn.value_proj          2.993676e+05   211.565000   \n",
       "         linear1                       1.907164e+06   755.916667   \n",
       "         linear2                       1.087157e+05  1477.720000   \n",
       "decoder  cross_attn.attention_weights  2.978128e+03   564.711667   \n",
       "         cross_attn.output_proj        5.137910e+03   241.780000   \n",
       "         cross_attn.sampling_offsets   4.469888e+03   582.711667   \n",
       "         cross_attn.value_proj         8.270184e+04    55.356667   \n",
       "         self_attn.k_proj              7.563838e+03   668.545000   \n",
       "         self_attn.out_proj            1.646522e+03   265.313333   \n",
       "         self_attn.q_proj              8.507283e+03   461.458333   \n",
       "         self_attn.v_proj              3.682638e+03    96.638333   \n",
       "         linear1                       6.408833e+01   489.408333   \n",
       "         linear2                       7.866667e+00  2114.028333   \n",
       "\n",
       "                                       normalized_error_gptq  \\\n",
       "sub_part trans_part                                            \n",
       "encoder  self_attn.attention_weights                2.187285   \n",
       "         self_attn.output_proj                      3.092043   \n",
       "         self_attn.sampling_offsets                 1.829126   \n",
       "         self_attn.value_proj                       4.567987   \n",
       "         linear1                                    3.637627   \n",
       "         linear2                                    0.207359   \n",
       "decoder  cross_attn.attention_weights               0.090885   \n",
       "         cross_attn.output_proj                     0.078398   \n",
       "         cross_attn.sampling_offsets                0.068205   \n",
       "         cross_attn.value_proj                      1.261930   \n",
       "         self_attn.k_proj                           0.115415   \n",
       "         self_attn.out_proj                         0.025124   \n",
       "         self_attn.q_proj                           0.129811   \n",
       "         self_attn.v_proj                           0.056193   \n",
       "         linear1                                    0.000122   \n",
       "         linear2                                    0.000015   \n",
       "\n",
       "                                       normalized_error_ldlq  \n",
       "sub_part trans_part                                           \n",
       "encoder  self_attn.attention_weights                0.011635  \n",
       "         self_attn.output_proj                      0.003337  \n",
       "         self_attn.sampling_offsets                 0.011386  \n",
       "         self_attn.value_proj                       0.003228  \n",
       "         linear1                                    0.001442  \n",
       "         linear2                                    0.002819  \n",
       "decoder  cross_attn.attention_weights               0.017234  \n",
       "         cross_attn.output_proj                     0.003689  \n",
       "         cross_attn.sampling_offsets                0.008891  \n",
       "         cross_attn.value_proj                      0.000845  \n",
       "         self_attn.k_proj                           0.010201  \n",
       "         self_attn.out_proj                         0.004048  \n",
       "         self_attn.q_proj                           0.007041  \n",
       "         self_attn.v_proj                           0.001475  \n",
       "         linear1                                    0.000933  \n",
       "         linear2                                    0.004032  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[[\"sub_part\", \"trans_part\", \"error_gptq\", \"error_ldlq\", \"normalized_error_gptq\", \"normalized_error_ldlq\"]].groupby([\"sub_part\", \"trans_part\"]).mean().sort_index(key=lambda x: x.str[5:]).loc[[\"encoder\", \"decoder\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = dino_swin[dino_swin.sub_part == \"backbone\"].copy()\n",
    "backbone = backbone[1:]\n",
    "backbone = backbone[~backbone.layer.str.contains(\"downsample\")]\n",
    "backbone[\"nb_layer\"] = backbone.layer.str.split('.', n=3).str[1].astype(int)\n",
    "backbone[\"nb_block\"] = backbone.layer.str.split('.', n=4).str[-2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th colspan=\"2\" halign=\"left\">number_of_parameters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.467895e+05</td>\n",
       "      <td>258.43125</td>\n",
       "      <td>3.031008</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>110592.0</td>\n",
       "      <td>884736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.302421e+05</td>\n",
       "      <td>989.88750</td>\n",
       "      <td>0.561575</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>442368.0</td>\n",
       "      <td>3538944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.187644e+06</td>\n",
       "      <td>1745.66000</td>\n",
       "      <td>2.627032</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>127401984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.843852e+06</td>\n",
       "      <td>3502.03125</td>\n",
       "      <td>0.408933</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>7077888.0</td>\n",
       "      <td>56623104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            error_gptq  error_ldlq normalized_error_gptq  \\\n",
       "                  mean        mean                  mean   \n",
       "nb_layer                                                   \n",
       "0         4.467895e+05   258.43125              3.031008   \n",
       "1         3.302421e+05   989.88750              0.561575   \n",
       "2         6.187644e+06  1745.66000              2.627032   \n",
       "3         3.843852e+06  3502.03125              0.408933   \n",
       "\n",
       "         normalized_error_ldlq number_of_parameters             \n",
       "                          mean                 mean        sum  \n",
       "nb_layer                                                        \n",
       "0                     0.002542             110592.0     884736  \n",
       "1                     0.002104             442368.0    3538944  \n",
       "2                     0.001049            1769472.0  127401984  \n",
       "3                     0.000719            7077888.0   56623104  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone[[\"nb_layer\", \"error_gptq\", \"error_ldlq\", \"normalized_error_gptq\", \"normalized_error_ldlq\", \"number_of_parameters\"]].groupby([\"nb_layer\"]).agg({\"error_gptq\": \"mean\", \"error_ldlq\": \"mean\", \"normalized_error_gptq\": \"mean\", \"normalized_error_ldlq\": \"mean\", \"number_of_parameters\": [\"mean\", \"sum\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th colspan=\"2\" halign=\"left\">number_of_parameters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_layer</th>\n",
       "      <th>nb_block</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>2.785724e+05</td>\n",
       "      <td>201.0175</td>\n",
       "      <td>1.889864</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>110592.0</td>\n",
       "      <td>442368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.150066e+05</td>\n",
       "      <td>315.8450</td>\n",
       "      <td>4.172151</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>110592.0</td>\n",
       "      <td>442368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>2.912884e+05</td>\n",
       "      <td>1100.7025</td>\n",
       "      <td>0.495004</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>442368.0</td>\n",
       "      <td>1769472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.691958e+05</td>\n",
       "      <td>879.0725</td>\n",
       "      <td>0.628147</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>442368.0</td>\n",
       "      <td>1769472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>3.238435e+04</td>\n",
       "      <td>3868.5375</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.898629e+04</td>\n",
       "      <td>3178.6100</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.049768e+04</td>\n",
       "      <td>2357.5950</td>\n",
       "      <td>0.034791</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.241036e+05</td>\n",
       "      <td>1879.1175</td>\n",
       "      <td>0.053099</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.802867e+05</td>\n",
       "      <td>1658.0775</td>\n",
       "      <td>0.077489</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.443197e+05</td>\n",
       "      <td>1008.1175</td>\n",
       "      <td>0.104824</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.219970e+05</td>\n",
       "      <td>1403.7600</td>\n",
       "      <td>0.138538</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.096598e+05</td>\n",
       "      <td>1840.8675</td>\n",
       "      <td>0.175640</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.084670e+05</td>\n",
       "      <td>2065.6100</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.179589e+05</td>\n",
       "      <td>1372.7725</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.066586e+05</td>\n",
       "      <td>1057.1025</td>\n",
       "      <td>0.304603</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.480975e+05</td>\n",
       "      <td>1109.6575</td>\n",
       "      <td>0.364780</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.921798e+06</td>\n",
       "      <td>1218.0875</td>\n",
       "      <td>1.669312</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.951393e+06</td>\n",
       "      <td>1196.7225</td>\n",
       "      <td>3.800812</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.497711e+07</td>\n",
       "      <td>1494.8950</td>\n",
       "      <td>6.357551</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.263464e+07</td>\n",
       "      <td>1243.5125</td>\n",
       "      <td>9.603120</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.775601e+07</td>\n",
       "      <td>1472.0650</td>\n",
       "      <td>11.774852</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.900322e+07</td>\n",
       "      <td>1996.7725</td>\n",
       "      <td>12.303802</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>1769472.0</td>\n",
       "      <td>7077888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>3.623058e+06</td>\n",
       "      <td>4213.0825</td>\n",
       "      <td>0.385230</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>7077888.0</td>\n",
       "      <td>28311552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.064646e+06</td>\n",
       "      <td>2790.9800</td>\n",
       "      <td>0.432636</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>7077888.0</td>\n",
       "      <td>28311552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     error_gptq error_ldlq normalized_error_gptq  \\\n",
       "                           mean       mean                  mean   \n",
       "nb_layer nb_block                                                  \n",
       "0        0         2.785724e+05   201.0175              1.889864   \n",
       "         1         6.150066e+05   315.8450              4.172151   \n",
       "1        0         2.912884e+05  1100.7025              0.495004   \n",
       "         1         3.691958e+05   879.0725              0.628147   \n",
       "2        0         3.238435e+04  3868.5375              0.013889   \n",
       "         1         5.898629e+04  3178.6100              0.025318   \n",
       "         2         8.049768e+04  2357.5950              0.034791   \n",
       "         3         1.241036e+05  1879.1175              0.053099   \n",
       "         4         1.802867e+05  1658.0775              0.077489   \n",
       "         5         2.443197e+05  1008.1175              0.104824   \n",
       "         6         3.219970e+05  1403.7600              0.138538   \n",
       "         7         4.096598e+05  1840.8675              0.175640   \n",
       "         8         5.084670e+05  2065.6100              0.218800   \n",
       "         9         6.179589e+05  1372.7725              0.265348   \n",
       "         10        7.066586e+05  1057.1025              0.304603   \n",
       "         11        8.480975e+05  1109.6575              0.364780   \n",
       "         12        3.921798e+06  1218.0875              1.669312   \n",
       "         13        8.951393e+06  1196.7225              3.800812   \n",
       "         14        1.497711e+07  1494.8950              6.357551   \n",
       "         15        2.263464e+07  1243.5125              9.603120   \n",
       "         16        2.775601e+07  1472.0650             11.774852   \n",
       "         17        2.900322e+07  1996.7725             12.303802   \n",
       "3        0         3.623058e+06  4213.0825              0.385230   \n",
       "         1         4.064646e+06  2790.9800              0.432636   \n",
       "\n",
       "                  normalized_error_ldlq number_of_parameters            \n",
       "                                   mean                 mean       sum  \n",
       "nb_layer nb_block                                                       \n",
       "0        0                     0.002155             110592.0    442368  \n",
       "         1                     0.002930             110592.0    442368  \n",
       "1        0                     0.002281             442368.0   1769472  \n",
       "         1                     0.001928             442368.0   1769472  \n",
       "2        0                     0.002073            1769472.0   7077888  \n",
       "         1                     0.001683            1769472.0   7077888  \n",
       "         2                     0.001341            1769472.0   7077888  \n",
       "         3                     0.001086            1769472.0   7077888  \n",
       "         4                     0.001057            1769472.0   7077888  \n",
       "         5                     0.000571            1769472.0   7077888  \n",
       "         6                     0.000838            1769472.0   7077888  \n",
       "         7                     0.001024            1769472.0   7077888  \n",
       "         8                     0.001167            1769472.0   7077888  \n",
       "         9                     0.000898            1769472.0   7077888  \n",
       "         10                    0.000717            1769472.0   7077888  \n",
       "         11                    0.000814            1769472.0   7077888  \n",
       "         12                    0.000817            1769472.0   7077888  \n",
       "         13                    0.000725            1769472.0   7077888  \n",
       "         14                    0.000943            1769472.0   7077888  \n",
       "         15                    0.000756            1769472.0   7077888  \n",
       "         16                    0.000901            1769472.0   7077888  \n",
       "         17                    0.001476            1769472.0   7077888  \n",
       "3        0                     0.000722            7077888.0  28311552  \n",
       "         1                     0.000717            7077888.0  28311552  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone[[\"nb_layer\", \"nb_block\", \"error_gptq\", \"error_ldlq\", \"normalized_error_gptq\", \"normalized_error_ldlq\", \"number_of_parameters\"]].groupby([\"nb_layer\", \"nb_block\"]).agg({\"error_gptq\": \"mean\", \"error_ldlq\": \"mean\", \"normalized_error_gptq\": \"mean\", \"normalized_error_ldlq\": \"mean\", \"number_of_parameters\": [\"mean\", \"sum\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>part</th>\n",
       "      <th>sub_part</th>\n",
       "      <th>number_of_parameters</th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Label_classifier</td>\n",
       "      <td>output_head</td>\n",
       "      <td>label_classifier</td>\n",
       "      <td>23296</td>\n",
       "      <td>2131.40</td>\n",
       "      <td>276.49</td>\n",
       "      <td>0.091492</td>\n",
       "      <td>0.011869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Bbox_predictor_layers.0</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>65536</td>\n",
       "      <td>3397.08</td>\n",
       "      <td>72.96</td>\n",
       "      <td>0.051835</td>\n",
       "      <td>0.001113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Bbox_predictor_layers.1</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>65536</td>\n",
       "      <td>3905.32</td>\n",
       "      <td>421.63</td>\n",
       "      <td>0.059590</td>\n",
       "      <td>0.006434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Bbox_predictor_layers.2</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>1024</td>\n",
       "      <td>42.34</td>\n",
       "      <td>75.18</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.073417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       layer         part          sub_part  \\\n",
       "200         Label_classifier  output_head  label_classifier   \n",
       "201  Bbox_predictor_layers.0  output_head    bbox_predictor   \n",
       "202  Bbox_predictor_layers.1  output_head    bbox_predictor   \n",
       "203  Bbox_predictor_layers.2  output_head    bbox_predictor   \n",
       "\n",
       "     number_of_parameters  error_gptq  error_ldlq  normalized_error_gptq  \\\n",
       "200                 23296     2131.40      276.49               0.091492   \n",
       "201                 65536     3397.08       72.96               0.051835   \n",
       "202                 65536     3905.32      421.63               0.059590   \n",
       "203                  1024       42.34       75.18               0.041350   \n",
       "\n",
       "     normalized_error_ldlq  \n",
       "200               0.011869  \n",
       "201               0.001113  \n",
       "202               0.006434  \n",
       "203               0.073417  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_head = dino_swin[dino_swin.part == \"output_head\"].copy()\n",
    "output_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Shot Quantization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_one_shot(s):\n",
    "  if s.startswith(\"backbone\") or  s.startswith(\"input_proj\"):\n",
    "    return \"backbone\"\n",
    "  elif s.startswith(\"transformer.enc_\"):\n",
    "    return \"query_selection\"\n",
    "  elif s.startswith(\"transformer\"):\n",
    "    return \"transformer\"\n",
    "  elif s.startswith(\"bbox_embed\") or s.startswith(\"class_embed\"):\n",
    "    return \"output_head\"\n",
    "\n",
    "def get_sub_part_one_shot(s):\n",
    "  if s.startswith(\"backbone\"):\n",
    "    return \"backbone\"\n",
    "  elif s.startswith(\"input_proj\"):\n",
    "    return \"input_projection\"\n",
    "  elif s.startswith(\"transformer.encoder.layer\"):\n",
    "    return \"encoder\"\n",
    "  elif s.startswith(\"transformer.decoder.layer\"):\n",
    "    return \"decoder\"\n",
    "  elif s.startswith(\"transformer.enc_\"):\n",
    "    return \"query_selection\"\n",
    "  elif s.startswith(\"bbox_embed\"):\n",
    "    return \"bbox_predictor\"\n",
    "  elif s.startswith(\"class_embed\"):\n",
    "    return \"label_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding layer number of parameters\n",
    "layers_one_shot = find_layers(model)\n",
    "number_of_parameters_one_shot = {k:int(v.weight.numel()) for k,v in layers_one_shot.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>part</th>\n",
       "      <th>sub_part</th>\n",
       "      <th>number_of_parameters</th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformer.encoder.layers.0.self_attn.samplin...</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>141620.66</td>\n",
       "      <td>987.35</td>\n",
       "      <td>2.160960e+00</td>\n",
       "      <td>0.015066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformer.encoder.layers.0.self_attn.attenti...</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>32768</td>\n",
       "      <td>79437.48</td>\n",
       "      <td>279.01</td>\n",
       "      <td>2.424240e+00</td>\n",
       "      <td>0.008515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformer.encoder.layers.0.self_attn.value_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>402241.97</td>\n",
       "      <td>277.82</td>\n",
       "      <td>6.137725e+00</td>\n",
       "      <td>0.004239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformer.encoder.layers.0.self_attn.output_...</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>148757.59</td>\n",
       "      <td>325.25</td>\n",
       "      <td>2.269861e+00</td>\n",
       "      <td>0.004963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformer.encoder.layers.0.linear1</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>524288</td>\n",
       "      <td>2670631.50</td>\n",
       "      <td>673.43</td>\n",
       "      <td>5.093825e+00</td>\n",
       "      <td>0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>backbone.0.layers.3.blocks.1.mlp.fc2</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>9437184</td>\n",
       "      <td>1845770.50</td>\n",
       "      <td>2278.65</td>\n",
       "      <td>1.955849e-01</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>bbox_embed.0.layers.0</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>65536</td>\n",
       "      <td>1.01</td>\n",
       "      <td>75.59</td>\n",
       "      <td>1.543198e-05</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>bbox_embed.0.layers.1</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>65536</td>\n",
       "      <td>0.01</td>\n",
       "      <td>394.18</td>\n",
       "      <td>1.893616e-07</td>\n",
       "      <td>0.006015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>bbox_embed.0.layers.2</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91.49</td>\n",
       "      <td>7.910156e-07</td>\n",
       "      <td>0.089341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>class_embed.0</td>\n",
       "      <td>output_head</td>\n",
       "      <td>label_classifier</td>\n",
       "      <td>23296</td>\n",
       "      <td>107.57</td>\n",
       "      <td>340.27</td>\n",
       "      <td>4.617525e-03</td>\n",
       "      <td>0.014607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 layer         part  \\\n",
       "0    transformer.encoder.layers.0.self_attn.samplin...  transformer   \n",
       "1    transformer.encoder.layers.0.self_attn.attenti...  transformer   \n",
       "2    transformer.encoder.layers.0.self_attn.value_proj  transformer   \n",
       "3    transformer.encoder.layers.0.self_attn.output_...  transformer   \n",
       "4                 transformer.encoder.layers.0.linear1  transformer   \n",
       "..                                                 ...          ...   \n",
       "210               backbone.0.layers.3.blocks.1.mlp.fc2     backbone   \n",
       "211                              bbox_embed.0.layers.0  output_head   \n",
       "212                              bbox_embed.0.layers.1  output_head   \n",
       "213                              bbox_embed.0.layers.2  output_head   \n",
       "214                                      class_embed.0  output_head   \n",
       "\n",
       "             sub_part  number_of_parameters  error_gptq  error_ldlq  \\\n",
       "0             encoder                 65536   141620.66      987.35   \n",
       "1             encoder                 32768    79437.48      279.01   \n",
       "2             encoder                 65536   402241.97      277.82   \n",
       "3             encoder                 65536   148757.59      325.25   \n",
       "4             encoder                524288  2670631.50      673.43   \n",
       "..                ...                   ...         ...         ...   \n",
       "210          backbone               9437184  1845770.50     2278.65   \n",
       "211    bbox_predictor                 65536        1.01       75.59   \n",
       "212    bbox_predictor                 65536        0.01      394.18   \n",
       "213    bbox_predictor                  1024        0.00       91.49   \n",
       "214  label_classifier                 23296      107.57      340.27   \n",
       "\n",
       "     normalized_error_gptq  normalized_error_ldlq  \n",
       "0             2.160960e+00               0.015066  \n",
       "1             2.424240e+00               0.008515  \n",
       "2             6.137725e+00               0.004239  \n",
       "3             2.269861e+00               0.004963  \n",
       "4             5.093825e+00               0.001284  \n",
       "..                     ...                    ...  \n",
       "210           1.955849e-01               0.000241  \n",
       "211           1.543198e-05               0.001153  \n",
       "212           1.893616e-07               0.006015  \n",
       "213           7.910156e-07               0.089341  \n",
       "214           4.617525e-03               0.014607  \n",
       "\n",
       "[209 rows x 8 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino_swin_ldlq_one_shot = pd.read_csv('errors/full_model_dino-swin-L_ldlq_IP_100samples_2bits.csv', names=[\"layer\", \"error_ldlq\"], header=0)\n",
    "dino_swin_gptq_one_shot = pd.read_csv('errors/full_model_dino-swin-L_gptq_100samples_2bits.csv', names=[\"layer\", \"error_gptq\"], header=0)\n",
    "dino_swin_one_shot = pd.merge(dino_swin_gptq_one_shot, dino_swin_ldlq_one_shot, on=\"layer\")\n",
    "dino_swin_one_shot = dino_swin_one_shot[~dino_swin_one_shot.layer.str.startswith(\"transformer.decoder.ref\")]\n",
    "dino_swin_one_shot = dino_swin_one_shot[~dino_swin_one_shot.layer.str.startswith(\"transformer.decoder.bbox\")]\n",
    "dino_swin_one_shot = dino_swin_one_shot[~dino_swin_one_shot.layer.str.startswith(\"transformer.decoder.class\")]\n",
    "dino_swin_one_shot[\"part\"] = dino_swin_one_shot.layer.apply(get_part_one_shot)\n",
    "dino_swin_one_shot[\"sub_part\"] = dino_swin_one_shot.layer.apply(get_sub_part_one_shot)\n",
    "dino_swin_one_shot[\"number_of_parameters\"] = dino_swin_one_shot.layer.apply(number_of_parameters_one_shot.get)\n",
    "dino_swin_one_shot[\"normalized_error_gptq\"] = dino_swin_one_shot.error_gptq / dino_swin_one_shot.number_of_parameters\n",
    "dino_swin_one_shot[\"normalized_error_ldlq\"] = dino_swin_one_shot.error_ldlq / dino_swin_one_shot.number_of_parameters\n",
    "dino_swin_one_shot[\"error_gptq\"] = dino_swin_one_shot.error_gptq.round(2)\n",
    "dino_swin_one_shot[\"error_ldlq\"] = dino_swin_one_shot.error_ldlq.round(2)\n",
    "dino_swin_one_shot = dino_swin_one_shot[[\"layer\", \"part\", \"sub_part\", \"number_of_parameters\", \"error_gptq\", \"error_ldlq\", \"normalized_error_gptq\", \"normalized_error_ldlq\"]]\n",
    "dino_swin_one_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>part</th>\n",
       "      <th>sub_part</th>\n",
       "      <th>number_of_parameters</th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Encoder_0_self_attn.sampling_offsets</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>141620.66</td>\n",
       "      <td>987.35</td>\n",
       "      <td>2.160960e+00</td>\n",
       "      <td>0.015066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Encoder_0_self_attn.attention_weights</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>32768</td>\n",
       "      <td>79437.48</td>\n",
       "      <td>279.01</td>\n",
       "      <td>2.424240e+00</td>\n",
       "      <td>0.008515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Encoder_0_self_attn.value_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>402241.97</td>\n",
       "      <td>277.82</td>\n",
       "      <td>6.137725e+00</td>\n",
       "      <td>0.004239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Encoder_0_self_attn.output_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>148757.59</td>\n",
       "      <td>325.25</td>\n",
       "      <td>2.269861e+00</td>\n",
       "      <td>0.004963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encoder_0_linear1</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>524288</td>\n",
       "      <td>2670631.50</td>\n",
       "      <td>673.43</td>\n",
       "      <td>5.093825e+00</td>\n",
       "      <td>0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Backbone_layers.3.blocks.1.mlp.fc2</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>9437184</td>\n",
       "      <td>1845770.50</td>\n",
       "      <td>2278.65</td>\n",
       "      <td>1.955849e-01</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Bbox_predictor_layers.0</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>65536</td>\n",
       "      <td>1.01</td>\n",
       "      <td>75.59</td>\n",
       "      <td>1.543198e-05</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Bbox_predictor_layers.1</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>65536</td>\n",
       "      <td>0.01</td>\n",
       "      <td>394.18</td>\n",
       "      <td>1.893616e-07</td>\n",
       "      <td>0.006015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Bbox_predictor_layers.2</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91.49</td>\n",
       "      <td>7.910156e-07</td>\n",
       "      <td>0.089341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Label_classifier</td>\n",
       "      <td>output_head</td>\n",
       "      <td>label_classifier</td>\n",
       "      <td>23296</td>\n",
       "      <td>107.57</td>\n",
       "      <td>340.27</td>\n",
       "      <td>4.617525e-03</td>\n",
       "      <td>0.014607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     layer         part          sub_part  \\\n",
       "0     Encoder_0_self_attn.sampling_offsets  transformer           encoder   \n",
       "1    Encoder_0_self_attn.attention_weights  transformer           encoder   \n",
       "2           Encoder_0_self_attn.value_proj  transformer           encoder   \n",
       "3          Encoder_0_self_attn.output_proj  transformer           encoder   \n",
       "4                        Encoder_0_linear1  transformer           encoder   \n",
       "..                                     ...          ...               ...   \n",
       "210     Backbone_layers.3.blocks.1.mlp.fc2     backbone          backbone   \n",
       "211                Bbox_predictor_layers.0  output_head    bbox_predictor   \n",
       "212                Bbox_predictor_layers.1  output_head    bbox_predictor   \n",
       "213                Bbox_predictor_layers.2  output_head    bbox_predictor   \n",
       "214                       Label_classifier  output_head  label_classifier   \n",
       "\n",
       "     number_of_parameters  error_gptq  error_ldlq  normalized_error_gptq  \\\n",
       "0                   65536   141620.66      987.35           2.160960e+00   \n",
       "1                   32768    79437.48      279.01           2.424240e+00   \n",
       "2                   65536   402241.97      277.82           6.137725e+00   \n",
       "3                   65536   148757.59      325.25           2.269861e+00   \n",
       "4                  524288  2670631.50      673.43           5.093825e+00   \n",
       "..                    ...         ...         ...                    ...   \n",
       "210               9437184  1845770.50     2278.65           1.955849e-01   \n",
       "211                 65536        1.01       75.59           1.543198e-05   \n",
       "212                 65536        0.01      394.18           1.893616e-07   \n",
       "213                  1024        0.00       91.49           7.910156e-07   \n",
       "214                 23296      107.57      340.27           4.617525e-03   \n",
       "\n",
       "     normalized_error_ldlq  \n",
       "0                 0.015066  \n",
       "1                 0.008515  \n",
       "2                 0.004239  \n",
       "3                 0.004963  \n",
       "4                 0.001284  \n",
       "..                     ...  \n",
       "210               0.000241  \n",
       "211               0.001153  \n",
       "212               0.006015  \n",
       "213               0.089341  \n",
       "214               0.014607  \n",
       "\n",
       "[209 rows x 8 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino_swin_one_shot.layer = dino_swin_one_shot.layer.str.replace(\"backbone.0.\", \"Backbone_\", regex=False)\n",
    "dino_swin_one_shot.layer = dino_swin_one_shot.layer.str.replace(\"bbox_embed.0.\", \"Bbox_predictor_\", regex=False)\n",
    "dino_swin_one_shot.layer = dino_swin_one_shot.layer.str.replace(\"class_embed.0\", \"Label_classifier\", regex=False)\n",
    "dino_swin_one_shot.layer = dino_swin_one_shot.layer.str.replace(\"input_proj.\", \"Input_projection_\", regex=False)\n",
    "dino_swin_one_shot.layer = dino_swin_one_shot.layer.str.replace(\"transformer.encoder.layers.\", \"Encoder_\", n=1, regex=False)\n",
    "dino_swin_one_shot.layer = dino_swin_one_shot.layer.str.replace(\"transformer.decoder.layers.\", \"Decoder_\", n=1, regex=False)\n",
    "dino_swin_one_shot.loc[dino_swin_one_shot.part == \"transformer\", \"layer\"] = dino_swin_one_shot[dino_swin_one_shot.part == \"transformer\"].layer.str.replace(\".\", \"_\", n=1, regex=False)\n",
    "dino_swin_one_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>part</th>\n",
       "      <th>sub_part</th>\n",
       "      <th>number_of_parameters</th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_gptq_one_shot</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>error_ldlq_one_shot</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_gptq_one_shot</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th>normalized_error_ldlq_one_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Backbone_patch_embed.proj</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>9216</td>\n",
       "      <td>40777.55</td>\n",
       "      <td>40777.55</td>\n",
       "      <td>76.48</td>\n",
       "      <td>68.18</td>\n",
       "      <td>4.424648</td>\n",
       "      <td>4.424648e+00</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.007398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Backbone_layers.0.blocks.0.attn.qkv</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>110592</td>\n",
       "      <td>242.70</td>\n",
       "      <td>242.70</td>\n",
       "      <td>185.70</td>\n",
       "      <td>184.35</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>2.194556e-03</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Backbone_layers.0.blocks.0.attn.proj</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>36864</td>\n",
       "      <td>105.53</td>\n",
       "      <td>105.53</td>\n",
       "      <td>134.97</td>\n",
       "      <td>130.62</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>2.862585e-03</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.003543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Backbone_layers.0.blocks.0.mlp.fc1</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>147456</td>\n",
       "      <td>846797.75</td>\n",
       "      <td>846797.75</td>\n",
       "      <td>155.21</td>\n",
       "      <td>154.96</td>\n",
       "      <td>5.742715</td>\n",
       "      <td>5.742715e+00</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Backbone_layers.0.blocks.0.mlp.fc2</td>\n",
       "      <td>backbone</td>\n",
       "      <td>backbone</td>\n",
       "      <td>147456</td>\n",
       "      <td>267143.69</td>\n",
       "      <td>267143.69</td>\n",
       "      <td>328.19</td>\n",
       "      <td>327.03</td>\n",
       "      <td>1.811684</td>\n",
       "      <td>1.811684e+00</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.002218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Decoder_5_linear2</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>524288</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.41</td>\n",
       "      <td>3306.48</td>\n",
       "      <td>3234.38</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>8.404236e-06</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.006169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Label_classifier</td>\n",
       "      <td>output_head</td>\n",
       "      <td>label_classifier</td>\n",
       "      <td>23296</td>\n",
       "      <td>2131.40</td>\n",
       "      <td>107.57</td>\n",
       "      <td>276.49</td>\n",
       "      <td>340.27</td>\n",
       "      <td>0.091492</td>\n",
       "      <td>4.617525e-03</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>0.014607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Bbox_predictor_layers.0</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>65536</td>\n",
       "      <td>3397.08</td>\n",
       "      <td>1.01</td>\n",
       "      <td>72.96</td>\n",
       "      <td>75.59</td>\n",
       "      <td>0.051835</td>\n",
       "      <td>1.543198e-05</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Bbox_predictor_layers.1</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>65536</td>\n",
       "      <td>3905.32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>421.63</td>\n",
       "      <td>394.18</td>\n",
       "      <td>0.059590</td>\n",
       "      <td>1.893616e-07</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.006015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Bbox_predictor_layers.2</td>\n",
       "      <td>output_head</td>\n",
       "      <td>bbox_predictor</td>\n",
       "      <td>1024</td>\n",
       "      <td>42.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.18</td>\n",
       "      <td>91.49</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>7.910156e-07</td>\n",
       "      <td>0.073417</td>\n",
       "      <td>0.089341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    layer         part          sub_part  \\\n",
       "0               Backbone_patch_embed.proj     backbone          backbone   \n",
       "1     Backbone_layers.0.blocks.0.attn.qkv     backbone          backbone   \n",
       "2    Backbone_layers.0.blocks.0.attn.proj     backbone          backbone   \n",
       "3      Backbone_layers.0.blocks.0.mlp.fc1     backbone          backbone   \n",
       "4      Backbone_layers.0.blocks.0.mlp.fc2     backbone          backbone   \n",
       "..                                    ...          ...               ...   \n",
       "199                     Decoder_5_linear2  transformer           decoder   \n",
       "200                      Label_classifier  output_head  label_classifier   \n",
       "201               Bbox_predictor_layers.0  output_head    bbox_predictor   \n",
       "202               Bbox_predictor_layers.1  output_head    bbox_predictor   \n",
       "203               Bbox_predictor_layers.2  output_head    bbox_predictor   \n",
       "\n",
       "     number_of_parameters  error_gptq  error_gptq_one_shot  error_ldlq  \\\n",
       "0                    9216    40777.55             40777.55       76.48   \n",
       "1                  110592      242.70               242.70      185.70   \n",
       "2                   36864      105.53               105.53      134.97   \n",
       "3                  147456   846797.75            846797.75      155.21   \n",
       "4                  147456   267143.69            267143.69      328.19   \n",
       "..                    ...         ...                  ...         ...   \n",
       "199                524288        4.32                 4.41     3306.48   \n",
       "200                 23296     2131.40               107.57      276.49   \n",
       "201                 65536     3397.08                 1.01       72.96   \n",
       "202                 65536     3905.32                 0.01      421.63   \n",
       "203                  1024       42.34                 0.00       75.18   \n",
       "\n",
       "     error_ldlq_one_shot  normalized_error_gptq  \\\n",
       "0                  68.18               4.424648   \n",
       "1                 184.35               0.002195   \n",
       "2                 130.62               0.002863   \n",
       "3                 154.96               5.742715   \n",
       "4                 327.03               1.811684   \n",
       "..                   ...                    ...   \n",
       "199              3234.38               0.000008   \n",
       "200               340.27               0.091492   \n",
       "201                75.59               0.051835   \n",
       "202               394.18               0.059590   \n",
       "203                91.49               0.041350   \n",
       "\n",
       "     normalized_error_gptq_one_shot  normalized_error_ldlq  \\\n",
       "0                      4.424648e+00               0.008299   \n",
       "1                      2.194556e-03               0.001679   \n",
       "2                      2.862585e-03               0.003661   \n",
       "3                      5.742715e+00               0.001053   \n",
       "4                      1.811684e+00               0.002226   \n",
       "..                              ...                    ...   \n",
       "199                    8.404236e-06               0.006307   \n",
       "200                    4.617525e-03               0.011869   \n",
       "201                    1.543198e-05               0.001113   \n",
       "202                    1.893616e-07               0.006434   \n",
       "203                    7.910156e-07               0.073417   \n",
       "\n",
       "     normalized_error_ldlq_one_shot  \n",
       "0                          0.007398  \n",
       "1                          0.001667  \n",
       "2                          0.003543  \n",
       "3                          0.001051  \n",
       "4                          0.002218  \n",
       "..                              ...  \n",
       "199                        0.006169  \n",
       "200                        0.014607  \n",
       "201                        0.001153  \n",
       "202                        0.006015  \n",
       "203                        0.089341  \n",
       "\n",
       "[204 rows x 12 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino_swin_merge = pd.merge(dino_swin, dino_swin_one_shot, on=[\"layer\", \"part\", \"sub_part\", \"number_of_parameters\"], suffixes=[\"\", \"_one_shot\"])\n",
    "dino_swin_merge = dino_swin_merge[[\"layer\", \"part\", \"sub_part\", \"number_of_parameters\", \"error_gptq\", \"error_gptq_one_shot\", \"error_ldlq\", \"error_ldlq_one_shot\", \"normalized_error_gptq\", \"normalized_error_gptq_one_shot\", \"normalized_error_ldlq\", \"normalized_error_ldlq_one_shot\"]]\n",
    "dino_swin_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = dino_swin_merge[dino_swin_merge.sub_part == \"backbone\"].copy()\n",
    "backbone = backbone[1:]\n",
    "backbone = backbone[~backbone.layer.str.contains(\"downsample\")]\n",
    "backbone[\"nb_layer\"] = backbone.layer.str.split('.', n=3).str[1].astype(int)\n",
    "backbone[\"nb_block\"] = backbone.layer.str.split('.', n=4).str[-2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_gptq_one_shot</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>error_ldlq_one_shot</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_gptq_one_shot</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th>normalized_error_ldlq_one_shot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.467895e+05</td>\n",
       "      <td>4.467895e+05</td>\n",
       "      <td>258.43125</td>\n",
       "      <td>257.256250</td>\n",
       "      <td>3.031008</td>\n",
       "      <td>3.031008</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.002528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.302421e+05</td>\n",
       "      <td>3.302421e+05</td>\n",
       "      <td>989.88750</td>\n",
       "      <td>985.531250</td>\n",
       "      <td>0.561575</td>\n",
       "      <td>0.561575</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.002102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.187644e+06</td>\n",
       "      <td>6.187644e+06</td>\n",
       "      <td>1745.66000</td>\n",
       "      <td>1748.634722</td>\n",
       "      <td>2.627032</td>\n",
       "      <td>2.627032</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.843852e+06</td>\n",
       "      <td>3.843852e+06</td>\n",
       "      <td>3502.03125</td>\n",
       "      <td>3502.766250</td>\n",
       "      <td>0.408933</td>\n",
       "      <td>0.408933</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            error_gptq  error_gptq_one_shot  error_ldlq  error_ldlq_one_shot  \\\n",
       "nb_layer                                                                       \n",
       "0         4.467895e+05         4.467895e+05   258.43125           257.256250   \n",
       "1         3.302421e+05         3.302421e+05   989.88750           985.531250   \n",
       "2         6.187644e+06         6.187644e+06  1745.66000          1748.634722   \n",
       "3         3.843852e+06         3.843852e+06  3502.03125          3502.766250   \n",
       "\n",
       "          normalized_error_gptq  normalized_error_gptq_one_shot  \\\n",
       "nb_layer                                                          \n",
       "0                      3.031008                        3.031008   \n",
       "1                      0.561575                        0.561575   \n",
       "2                      2.627032                        2.627032   \n",
       "3                      0.408933                        0.408933   \n",
       "\n",
       "          normalized_error_ldlq  normalized_error_ldlq_one_shot  \n",
       "nb_layer                                                         \n",
       "0                      0.002542                        0.002528  \n",
       "1                      0.002104                        0.002102  \n",
       "2                      0.001049                        0.001051  \n",
       "3                      0.000719                        0.000719  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone[[\"nb_layer\", \"error_gptq\", \"error_gptq_one_shot\", \"error_ldlq\", \"error_ldlq_one_shot\", \"normalized_error_gptq\", \"normalized_error_gptq_one_shot\", \"normalized_error_ldlq\", \"normalized_error_ldlq_one_shot\"]].groupby([\"nb_layer\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_gptq_one_shot</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>error_ldlq_one_shot</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_gptq_one_shot</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th>normalized_error_ldlq_one_shot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_layer</th>\n",
       "      <th>nb_block</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>2.785724e+05</td>\n",
       "      <td>2.785724e+05</td>\n",
       "      <td>201.0175</td>\n",
       "      <td>199.2400</td>\n",
       "      <td>1.889864</td>\n",
       "      <td>1.889864</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.002120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.150066e+05</td>\n",
       "      <td>6.150066e+05</td>\n",
       "      <td>315.8450</td>\n",
       "      <td>315.2725</td>\n",
       "      <td>4.172151</td>\n",
       "      <td>4.172151</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>2.912884e+05</td>\n",
       "      <td>2.912884e+05</td>\n",
       "      <td>1100.7025</td>\n",
       "      <td>1101.1850</td>\n",
       "      <td>0.495004</td>\n",
       "      <td>0.495004</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.691958e+05</td>\n",
       "      <td>3.691958e+05</td>\n",
       "      <td>879.0725</td>\n",
       "      <td>869.8775</td>\n",
       "      <td>0.628147</td>\n",
       "      <td>0.628147</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.001919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>3.238435e+04</td>\n",
       "      <td>3.238435e+04</td>\n",
       "      <td>3868.5375</td>\n",
       "      <td>3897.8275</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.002085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.898629e+04</td>\n",
       "      <td>5.898629e+04</td>\n",
       "      <td>3178.6100</td>\n",
       "      <td>3210.6975</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>0.025318</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.001695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.049768e+04</td>\n",
       "      <td>8.049768e+04</td>\n",
       "      <td>2357.5950</td>\n",
       "      <td>2355.5425</td>\n",
       "      <td>0.034791</td>\n",
       "      <td>0.034791</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.241036e+05</td>\n",
       "      <td>1.241036e+05</td>\n",
       "      <td>1879.1175</td>\n",
       "      <td>1873.3150</td>\n",
       "      <td>0.053099</td>\n",
       "      <td>0.053099</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.001085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.802867e+05</td>\n",
       "      <td>1.802867e+05</td>\n",
       "      <td>1658.0775</td>\n",
       "      <td>1657.2550</td>\n",
       "      <td>0.077489</td>\n",
       "      <td>0.077489</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.001055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.443197e+05</td>\n",
       "      <td>2.443197e+05</td>\n",
       "      <td>1008.1175</td>\n",
       "      <td>1006.1350</td>\n",
       "      <td>0.104824</td>\n",
       "      <td>0.104824</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.219970e+05</td>\n",
       "      <td>3.219970e+05</td>\n",
       "      <td>1403.7600</td>\n",
       "      <td>1402.6325</td>\n",
       "      <td>0.138538</td>\n",
       "      <td>0.138538</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.096598e+05</td>\n",
       "      <td>4.096598e+05</td>\n",
       "      <td>1840.8675</td>\n",
       "      <td>1845.2500</td>\n",
       "      <td>0.175640</td>\n",
       "      <td>0.175640</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.001026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.084670e+05</td>\n",
       "      <td>5.084670e+05</td>\n",
       "      <td>2065.6100</td>\n",
       "      <td>2070.9425</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.179589e+05</td>\n",
       "      <td>6.179589e+05</td>\n",
       "      <td>1372.7725</td>\n",
       "      <td>1365.2250</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.066586e+05</td>\n",
       "      <td>7.066586e+05</td>\n",
       "      <td>1057.1025</td>\n",
       "      <td>1057.9275</td>\n",
       "      <td>0.304603</td>\n",
       "      <td>0.304603</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.480975e+05</td>\n",
       "      <td>8.480975e+05</td>\n",
       "      <td>1109.6575</td>\n",
       "      <td>1109.8725</td>\n",
       "      <td>0.364780</td>\n",
       "      <td>0.364780</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.921798e+06</td>\n",
       "      <td>3.921798e+06</td>\n",
       "      <td>1218.0875</td>\n",
       "      <td>1222.3825</td>\n",
       "      <td>1.669312</td>\n",
       "      <td>1.669312</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.951393e+06</td>\n",
       "      <td>8.951393e+06</td>\n",
       "      <td>1196.7225</td>\n",
       "      <td>1194.8725</td>\n",
       "      <td>3.800812</td>\n",
       "      <td>3.800812</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.497711e+07</td>\n",
       "      <td>1.497711e+07</td>\n",
       "      <td>1494.8950</td>\n",
       "      <td>1491.5825</td>\n",
       "      <td>6.357551</td>\n",
       "      <td>6.357551</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.263464e+07</td>\n",
       "      <td>2.263464e+07</td>\n",
       "      <td>1243.5125</td>\n",
       "      <td>1243.3675</td>\n",
       "      <td>9.603120</td>\n",
       "      <td>9.603120</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.775601e+07</td>\n",
       "      <td>2.775601e+07</td>\n",
       "      <td>1472.0650</td>\n",
       "      <td>1474.0725</td>\n",
       "      <td>11.774852</td>\n",
       "      <td>11.774852</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.900322e+07</td>\n",
       "      <td>2.900322e+07</td>\n",
       "      <td>1996.7725</td>\n",
       "      <td>1996.5250</td>\n",
       "      <td>12.303802</td>\n",
       "      <td>12.303802</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>3.623058e+06</td>\n",
       "      <td>3.623058e+06</td>\n",
       "      <td>4213.0825</td>\n",
       "      <td>4219.9375</td>\n",
       "      <td>0.385230</td>\n",
       "      <td>0.385230</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.064646e+06</td>\n",
       "      <td>4.064646e+06</td>\n",
       "      <td>2790.9800</td>\n",
       "      <td>2785.5950</td>\n",
       "      <td>0.432636</td>\n",
       "      <td>0.432636</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     error_gptq  error_gptq_one_shot  error_ldlq  \\\n",
       "nb_layer nb_block                                                  \n",
       "0        0         2.785724e+05         2.785724e+05    201.0175   \n",
       "         1         6.150066e+05         6.150066e+05    315.8450   \n",
       "1        0         2.912884e+05         2.912884e+05   1100.7025   \n",
       "         1         3.691958e+05         3.691958e+05    879.0725   \n",
       "2        0         3.238435e+04         3.238435e+04   3868.5375   \n",
       "         1         5.898629e+04         5.898629e+04   3178.6100   \n",
       "         2         8.049768e+04         8.049768e+04   2357.5950   \n",
       "         3         1.241036e+05         1.241036e+05   1879.1175   \n",
       "         4         1.802867e+05         1.802867e+05   1658.0775   \n",
       "         5         2.443197e+05         2.443197e+05   1008.1175   \n",
       "         6         3.219970e+05         3.219970e+05   1403.7600   \n",
       "         7         4.096598e+05         4.096598e+05   1840.8675   \n",
       "         8         5.084670e+05         5.084670e+05   2065.6100   \n",
       "         9         6.179589e+05         6.179589e+05   1372.7725   \n",
       "         10        7.066586e+05         7.066586e+05   1057.1025   \n",
       "         11        8.480975e+05         8.480975e+05   1109.6575   \n",
       "         12        3.921798e+06         3.921798e+06   1218.0875   \n",
       "         13        8.951393e+06         8.951393e+06   1196.7225   \n",
       "         14        1.497711e+07         1.497711e+07   1494.8950   \n",
       "         15        2.263464e+07         2.263464e+07   1243.5125   \n",
       "         16        2.775601e+07         2.775601e+07   1472.0650   \n",
       "         17        2.900322e+07         2.900322e+07   1996.7725   \n",
       "3        0         3.623058e+06         3.623058e+06   4213.0825   \n",
       "         1         4.064646e+06         4.064646e+06   2790.9800   \n",
       "\n",
       "                   error_ldlq_one_shot  normalized_error_gptq  \\\n",
       "nb_layer nb_block                                               \n",
       "0        0                    199.2400               1.889864   \n",
       "         1                    315.2725               4.172151   \n",
       "1        0                   1101.1850               0.495004   \n",
       "         1                    869.8775               0.628147   \n",
       "2        0                   3897.8275               0.013889   \n",
       "         1                   3210.6975               0.025318   \n",
       "         2                   2355.5425               0.034791   \n",
       "         3                   1873.3150               0.053099   \n",
       "         4                   1657.2550               0.077489   \n",
       "         5                   1006.1350               0.104824   \n",
       "         6                   1402.6325               0.138538   \n",
       "         7                   1845.2500               0.175640   \n",
       "         8                   2070.9425               0.218800   \n",
       "         9                   1365.2250               0.265348   \n",
       "         10                  1057.9275               0.304603   \n",
       "         11                  1109.8725               0.364780   \n",
       "         12                  1222.3825               1.669312   \n",
       "         13                  1194.8725               3.800812   \n",
       "         14                  1491.5825               6.357551   \n",
       "         15                  1243.3675               9.603120   \n",
       "         16                  1474.0725              11.774852   \n",
       "         17                  1996.5250              12.303802   \n",
       "3        0                   4219.9375               0.385230   \n",
       "         1                   2785.5950               0.432636   \n",
       "\n",
       "                   normalized_error_gptq_one_shot  normalized_error_ldlq  \\\n",
       "nb_layer nb_block                                                          \n",
       "0        0                               1.889864               0.002155   \n",
       "         1                               4.172151               0.002930   \n",
       "1        0                               0.495004               0.002281   \n",
       "         1                               0.628147               0.001928   \n",
       "2        0                               0.013889               0.002073   \n",
       "         1                               0.025318               0.001683   \n",
       "         2                               0.034791               0.001341   \n",
       "         3                               0.053099               0.001086   \n",
       "         4                               0.077489               0.001057   \n",
       "         5                               0.104824               0.000571   \n",
       "         6                               0.138538               0.000838   \n",
       "         7                               0.175640               0.001024   \n",
       "         8                               0.218800               0.001167   \n",
       "         9                               0.265348               0.000898   \n",
       "         10                              0.304603               0.000717   \n",
       "         11                              0.364780               0.000814   \n",
       "         12                              1.669312               0.000817   \n",
       "         13                              3.800812               0.000725   \n",
       "         14                              6.357551               0.000943   \n",
       "         15                              9.603120               0.000756   \n",
       "         16                             11.774852               0.000901   \n",
       "         17                             12.303802               0.001476   \n",
       "3        0                               0.385230               0.000722   \n",
       "         1                               0.432636               0.000717   \n",
       "\n",
       "                   normalized_error_ldlq_one_shot  \n",
       "nb_layer nb_block                                  \n",
       "0        0                               0.002120  \n",
       "         1                               0.002936  \n",
       "1        0                               0.002284  \n",
       "         1                               0.001919  \n",
       "2        0                               0.002085  \n",
       "         1                               0.001695  \n",
       "         2                               0.001339  \n",
       "         3                               0.001085  \n",
       "         4                               0.001055  \n",
       "         5                               0.000571  \n",
       "         6                               0.000835  \n",
       "         7                               0.001026  \n",
       "         8                               0.001170  \n",
       "         9                               0.000895  \n",
       "         10                              0.000717  \n",
       "         11                              0.000816  \n",
       "         12                              0.000820  \n",
       "         13                              0.000723  \n",
       "         14                              0.000942  \n",
       "         15                              0.000756  \n",
       "         16                              0.000901  \n",
       "         17                              0.001479  \n",
       "3        0                               0.000724  \n",
       "         1                               0.000714  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone[[\"nb_layer\", \"nb_block\", \"error_gptq\", \"error_gptq_one_shot\", \"error_ldlq\", \"error_ldlq_one_shot\", \"normalized_error_gptq\", \"normalized_error_gptq_one_shot\", \"normalized_error_ldlq\", \"normalized_error_ldlq_one_shot\"]].groupby([\"nb_layer\", \"nb_block\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>part</th>\n",
       "      <th>sub_part</th>\n",
       "      <th>number_of_parameters</th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_gptq_one_shot</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>error_ldlq_one_shot</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_gptq_one_shot</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th>normalized_error_ldlq_one_shot</th>\n",
       "      <th>trans_part</th>\n",
       "      <th>nb_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Encoder_0_self_attn.sampling_offsets</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>141620.66</td>\n",
       "      <td>141620.66</td>\n",
       "      <td>1009.97</td>\n",
       "      <td>987.35</td>\n",
       "      <td>2.160960</td>\n",
       "      <td>2.160960</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>self_attn.sampling_offsets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Encoder_0_self_attn.attention_weights</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>32768</td>\n",
       "      <td>79437.48</td>\n",
       "      <td>79437.48</td>\n",
       "      <td>300.39</td>\n",
       "      <td>279.01</td>\n",
       "      <td>2.424240</td>\n",
       "      <td>2.424240</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.008515</td>\n",
       "      <td>self_attn.attention_weights</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Encoder_0_self_attn.value_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>402241.97</td>\n",
       "      <td>402241.97</td>\n",
       "      <td>270.40</td>\n",
       "      <td>277.82</td>\n",
       "      <td>6.137725</td>\n",
       "      <td>6.137725</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>self_attn.value_proj</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Encoder_0_self_attn.output_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>148757.59</td>\n",
       "      <td>148757.59</td>\n",
       "      <td>338.27</td>\n",
       "      <td>325.25</td>\n",
       "      <td>2.269861</td>\n",
       "      <td>2.269861</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>self_attn.output_proj</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Encoder_0_linear1</td>\n",
       "      <td>transformer</td>\n",
       "      <td>encoder</td>\n",
       "      <td>524288</td>\n",
       "      <td>2670631.50</td>\n",
       "      <td>2670631.50</td>\n",
       "      <td>678.41</td>\n",
       "      <td>673.43</td>\n",
       "      <td>5.093825</td>\n",
       "      <td>5.093825</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>linear1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Decoder_5_self_attn.v_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>2927.71</td>\n",
       "      <td>2540.75</td>\n",
       "      <td>27.40</td>\n",
       "      <td>26.07</td>\n",
       "      <td>0.044673</td>\n",
       "      <td>0.038769</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>self_attn.v_proj</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Decoder_5_self_attn.q_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>14565.74</td>\n",
       "      <td>13603.20</td>\n",
       "      <td>1225.72</td>\n",
       "      <td>1269.69</td>\n",
       "      <td>0.222256</td>\n",
       "      <td>0.207568</td>\n",
       "      <td>0.018703</td>\n",
       "      <td>0.019374</td>\n",
       "      <td>self_attn.q_proj</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Decoder_5_self_attn.out_proj</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>65536</td>\n",
       "      <td>1646.92</td>\n",
       "      <td>1752.32</td>\n",
       "      <td>238.05</td>\n",
       "      <td>209.69</td>\n",
       "      <td>0.025130</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>self_attn.out_proj</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Decoder_5_linear1</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>524288</td>\n",
       "      <td>48.92</td>\n",
       "      <td>46.92</td>\n",
       "      <td>467.12</td>\n",
       "      <td>457.56</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>linear1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Decoder_5_linear2</td>\n",
       "      <td>transformer</td>\n",
       "      <td>decoder</td>\n",
       "      <td>524288</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.41</td>\n",
       "      <td>3306.48</td>\n",
       "      <td>3234.38</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>linear2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     layer         part sub_part  \\\n",
       "104   Encoder_0_self_attn.sampling_offsets  transformer  encoder   \n",
       "105  Encoder_0_self_attn.attention_weights  transformer  encoder   \n",
       "106         Encoder_0_self_attn.value_proj  transformer  encoder   \n",
       "107        Encoder_0_self_attn.output_proj  transformer  encoder   \n",
       "108                      Encoder_0_linear1  transformer  encoder   \n",
       "..                                     ...          ...      ...   \n",
       "195             Decoder_5_self_attn.v_proj  transformer  decoder   \n",
       "196             Decoder_5_self_attn.q_proj  transformer  decoder   \n",
       "197           Decoder_5_self_attn.out_proj  transformer  decoder   \n",
       "198                      Decoder_5_linear1  transformer  decoder   \n",
       "199                      Decoder_5_linear2  transformer  decoder   \n",
       "\n",
       "     number_of_parameters  error_gptq  error_gptq_one_shot  error_ldlq  \\\n",
       "104                 65536   141620.66            141620.66     1009.97   \n",
       "105                 32768    79437.48             79437.48      300.39   \n",
       "106                 65536   402241.97            402241.97      270.40   \n",
       "107                 65536   148757.59            148757.59      338.27   \n",
       "108                524288  2670631.50           2670631.50      678.41   \n",
       "..                    ...         ...                  ...         ...   \n",
       "195                 65536     2927.71              2540.75       27.40   \n",
       "196                 65536    14565.74             13603.20     1225.72   \n",
       "197                 65536     1646.92              1752.32      238.05   \n",
       "198                524288       48.92                46.92      467.12   \n",
       "199                524288        4.32                 4.41     3306.48   \n",
       "\n",
       "     error_ldlq_one_shot  normalized_error_gptq  \\\n",
       "104               987.35               2.160960   \n",
       "105               279.01               2.424240   \n",
       "106               277.82               6.137725   \n",
       "107               325.25               2.269861   \n",
       "108               673.43               5.093825   \n",
       "..                   ...                    ...   \n",
       "195                26.07               0.044673   \n",
       "196              1269.69               0.222256   \n",
       "197               209.69               0.025130   \n",
       "198               457.56               0.000093   \n",
       "199              3234.38               0.000008   \n",
       "\n",
       "     normalized_error_gptq_one_shot  normalized_error_ldlq  \\\n",
       "104                        2.160960               0.015411   \n",
       "105                        2.424240               0.009167   \n",
       "106                        6.137725               0.004126   \n",
       "107                        2.269861               0.005162   \n",
       "108                        5.093825               0.001294   \n",
       "..                              ...                    ...   \n",
       "195                        0.038769               0.000418   \n",
       "196                        0.207568               0.018703   \n",
       "197                        0.026738               0.003632   \n",
       "198                        0.000089               0.000891   \n",
       "199                        0.000008               0.006307   \n",
       "\n",
       "     normalized_error_ldlq_one_shot                   trans_part  nb_layer  \n",
       "104                        0.015066   self_attn.sampling_offsets         0  \n",
       "105                        0.008515  self_attn.attention_weights         0  \n",
       "106                        0.004239         self_attn.value_proj         0  \n",
       "107                        0.004963        self_attn.output_proj         0  \n",
       "108                        0.001284                      linear1         0  \n",
       "..                              ...                          ...       ...  \n",
       "195                        0.000398             self_attn.v_proj         5  \n",
       "196                        0.019374             self_attn.q_proj         5  \n",
       "197                        0.003200           self_attn.out_proj         5  \n",
       "198                        0.000873                      linear1         5  \n",
       "199                        0.006169                      linear2         5  \n",
       "\n",
       "[96 rows x 14 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = dino_swin_merge[dino_swin_merge.part == \"transformer\"].copy()\n",
    "trans[\"trans_part\"] = trans.layer.str.split('_', n=2).str[-1]\n",
    "trans[\"nb_layer\"] = trans.layer.str.split('_', n=3).str[1].astype(int)\n",
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_gptq_one_shot</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>error_ldlq_one_shot</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_gptq_one_shot</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th>normalized_error_ldlq_one_shot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_part</th>\n",
       "      <th>nb_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">encoder</th>\n",
       "      <th>0</th>\n",
       "      <td>599228.280000</td>\n",
       "      <td>599228.280000</td>\n",
       "      <td>719.701667</td>\n",
       "      <td>714.110000</td>\n",
       "      <td>3.062971</td>\n",
       "      <td>3.062971</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>0.006232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540224.816667</td>\n",
       "      <td>510316.486667</td>\n",
       "      <td>641.108333</td>\n",
       "      <td>647.080000</td>\n",
       "      <td>2.877755</td>\n",
       "      <td>2.686860</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.006015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>438957.775000</td>\n",
       "      <td>392107.373333</td>\n",
       "      <td>667.448333</td>\n",
       "      <td>686.580000</td>\n",
       "      <td>2.475449</td>\n",
       "      <td>2.168611</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>437630.778333</td>\n",
       "      <td>380258.250000</td>\n",
       "      <td>601.911667</td>\n",
       "      <td>609.460000</td>\n",
       "      <td>2.219882</td>\n",
       "      <td>1.882374</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.004850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>414707.791667</td>\n",
       "      <td>358661.191667</td>\n",
       "      <td>613.710000</td>\n",
       "      <td>590.323333</td>\n",
       "      <td>2.783273</td>\n",
       "      <td>2.348546</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.005522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>278684.673333</td>\n",
       "      <td>246426.546667</td>\n",
       "      <td>547.483333</td>\n",
       "      <td>570.741667</td>\n",
       "      <td>2.102096</td>\n",
       "      <td>1.800466</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.005399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">decoder</th>\n",
       "      <th>0</th>\n",
       "      <td>13176.294000</td>\n",
       "      <td>11498.637000</td>\n",
       "      <td>737.988000</td>\n",
       "      <td>748.897000</td>\n",
       "      <td>0.201975</td>\n",
       "      <td>0.176374</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>0.009685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11499.625000</td>\n",
       "      <td>10007.013000</td>\n",
       "      <td>427.407000</td>\n",
       "      <td>442.010000</td>\n",
       "      <td>0.179450</td>\n",
       "      <td>0.156402</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.004558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11667.025000</td>\n",
       "      <td>10043.829000</td>\n",
       "      <td>319.919000</td>\n",
       "      <td>332.241000</td>\n",
       "      <td>0.183686</td>\n",
       "      <td>0.158156</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.003291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11852.527000</td>\n",
       "      <td>10157.759000</td>\n",
       "      <td>405.243000</td>\n",
       "      <td>426.145000</td>\n",
       "      <td>0.186188</td>\n",
       "      <td>0.159681</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10624.167000</td>\n",
       "      <td>9159.858000</td>\n",
       "      <td>511.153000</td>\n",
       "      <td>505.398000</td>\n",
       "      <td>0.167217</td>\n",
       "      <td>0.144411</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.004204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11236.361000</td>\n",
       "      <td>9887.736000</td>\n",
       "      <td>922.261000</td>\n",
       "      <td>915.857000</td>\n",
       "      <td>0.177143</td>\n",
       "      <td>0.156338</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.009570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      error_gptq  error_gptq_one_shot  error_ldlq  \\\n",
       "sub_part nb_layer                                                   \n",
       "encoder  0         599228.280000        599228.280000  719.701667   \n",
       "         1         540224.816667        510316.486667  641.108333   \n",
       "         2         438957.775000        392107.373333  667.448333   \n",
       "         3         437630.778333        380258.250000  601.911667   \n",
       "         4         414707.791667        358661.191667  613.710000   \n",
       "         5         278684.673333        246426.546667  547.483333   \n",
       "decoder  0          13176.294000         11498.637000  737.988000   \n",
       "         1          11499.625000         10007.013000  427.407000   \n",
       "         2          11667.025000         10043.829000  319.919000   \n",
       "         3          11852.527000         10157.759000  405.243000   \n",
       "         4          10624.167000          9159.858000  511.153000   \n",
       "         5          11236.361000          9887.736000  922.261000   \n",
       "\n",
       "                   error_ldlq_one_shot  normalized_error_gptq  \\\n",
       "sub_part nb_layer                                               \n",
       "encoder  0                  714.110000               3.062971   \n",
       "         1                  647.080000               2.877755   \n",
       "         2                  686.580000               2.475449   \n",
       "         3                  609.460000               2.219882   \n",
       "         4                  590.323333               2.783273   \n",
       "         5                  570.741667               2.102096   \n",
       "decoder  0                  748.897000               0.201975   \n",
       "         1                  442.010000               0.179450   \n",
       "         2                  332.241000               0.183686   \n",
       "         3                  426.145000               0.186188   \n",
       "         4                  505.398000               0.167217   \n",
       "         5                  915.857000               0.177143   \n",
       "\n",
       "                   normalized_error_gptq_one_shot  normalized_error_ldlq  \\\n",
       "sub_part nb_layer                                                          \n",
       "encoder  0                               3.062971               0.006407   \n",
       "         1                               2.686860               0.005941   \n",
       "         2                               2.168611               0.005994   \n",
       "         3                               1.882374               0.004731   \n",
       "         4                               2.348546               0.005531   \n",
       "         5                               1.800466               0.005242   \n",
       "decoder  0                               0.176374               0.009778   \n",
       "         1                               0.156402               0.004458   \n",
       "         2                               0.158156               0.003265   \n",
       "         3                               0.159681               0.003787   \n",
       "         4                               0.144411               0.004231   \n",
       "         5                               0.156338               0.009515   \n",
       "\n",
       "                   normalized_error_ldlq_one_shot  \n",
       "sub_part nb_layer                                  \n",
       "encoder  0                               0.006232  \n",
       "         1                               0.006015  \n",
       "         2                               0.006210  \n",
       "         3                               0.004850  \n",
       "         4                               0.005522  \n",
       "         5                               0.005399  \n",
       "decoder  0                               0.009685  \n",
       "         1                               0.004558  \n",
       "         2                               0.003291  \n",
       "         3                               0.003772  \n",
       "         4                               0.004204  \n",
       "         5                               0.009570  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[[\"sub_part\", \"nb_layer\", \"error_gptq\", \"error_gptq_one_shot\", \"error_ldlq\", \"error_ldlq_one_shot\", \"normalized_error_gptq\", \"normalized_error_gptq_one_shot\", \"normalized_error_ldlq\", \"normalized_error_ldlq_one_shot\"]].groupby([\"sub_part\", \"nb_layer\"]).mean().loc[[\"encoder\", \"decoder\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>error_gptq</th>\n",
       "      <th>error_gptq_one_shot</th>\n",
       "      <th>error_ldlq</th>\n",
       "      <th>error_ldlq_one_shot</th>\n",
       "      <th>normalized_error_gptq</th>\n",
       "      <th>normalized_error_gptq_one_shot</th>\n",
       "      <th>normalized_error_ldlq</th>\n",
       "      <th>normalized_error_ldlq_one_shot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_part</th>\n",
       "      <th>trans_part</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">encoder</th>\n",
       "      <th>self_attn.attention_weights</th>\n",
       "      <td>7.167297e+04</td>\n",
       "      <td>6.224906e+04</td>\n",
       "      <td>381.266667</td>\n",
       "      <td>388.288333</td>\n",
       "      <td>2.187285</td>\n",
       "      <td>1.899690</td>\n",
       "      <td>0.011635</td>\n",
       "      <td>0.011850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.output_proj</th>\n",
       "      <td>2.026401e+05</td>\n",
       "      <td>1.926753e+05</td>\n",
       "      <td>218.688333</td>\n",
       "      <td>213.981667</td>\n",
       "      <td>3.092043</td>\n",
       "      <td>2.939992</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.003265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.sampling_offsets</th>\n",
       "      <td>1.198736e+05</td>\n",
       "      <td>1.045355e+05</td>\n",
       "      <td>746.206667</td>\n",
       "      <td>758.101667</td>\n",
       "      <td>1.829126</td>\n",
       "      <td>1.595086</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>0.011568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.value_proj</th>\n",
       "      <td>2.993676e+05</td>\n",
       "      <td>2.589311e+05</td>\n",
       "      <td>211.565000</td>\n",
       "      <td>213.966667</td>\n",
       "      <td>4.567987</td>\n",
       "      <td>3.950976</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>0.003265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear1</th>\n",
       "      <td>1.907164e+06</td>\n",
       "      <td>1.755922e+06</td>\n",
       "      <td>755.916667</td>\n",
       "      <td>744.575000</td>\n",
       "      <td>3.637627</td>\n",
       "      <td>3.349155</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.001420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear2</th>\n",
       "      <td>1.087157e+05</td>\n",
       "      <td>1.126851e+05</td>\n",
       "      <td>1477.720000</td>\n",
       "      <td>1499.381667</td>\n",
       "      <td>0.207359</td>\n",
       "      <td>0.214930</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.002860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">decoder</th>\n",
       "      <th>cross_attn.attention_weights</th>\n",
       "      <td>2.978128e+03</td>\n",
       "      <td>2.716760e+03</td>\n",
       "      <td>564.711667</td>\n",
       "      <td>565.701667</td>\n",
       "      <td>0.090885</td>\n",
       "      <td>0.082909</td>\n",
       "      <td>0.017234</td>\n",
       "      <td>0.017264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_attn.output_proj</th>\n",
       "      <td>5.137910e+03</td>\n",
       "      <td>5.186345e+03</td>\n",
       "      <td>241.780000</td>\n",
       "      <td>244.443333</td>\n",
       "      <td>0.078398</td>\n",
       "      <td>0.079137</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.003730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_attn.sampling_offsets</th>\n",
       "      <td>4.469888e+03</td>\n",
       "      <td>4.082293e+03</td>\n",
       "      <td>582.711667</td>\n",
       "      <td>571.501667</td>\n",
       "      <td>0.068205</td>\n",
       "      <td>0.062291</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.008720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_attn.value_proj</th>\n",
       "      <td>8.270184e+04</td>\n",
       "      <td>7.025100e+04</td>\n",
       "      <td>55.356667</td>\n",
       "      <td>56.888333</td>\n",
       "      <td>1.261930</td>\n",
       "      <td>1.071945</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.k_proj</th>\n",
       "      <td>7.563838e+03</td>\n",
       "      <td>6.667278e+03</td>\n",
       "      <td>668.545000</td>\n",
       "      <td>664.425000</td>\n",
       "      <td>0.115415</td>\n",
       "      <td>0.101735</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>0.010138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.out_proj</th>\n",
       "      <td>1.646522e+03</td>\n",
       "      <td>1.643693e+03</td>\n",
       "      <td>265.313333</td>\n",
       "      <td>260.726667</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>0.025081</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>0.003978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.q_proj</th>\n",
       "      <td>8.507283e+03</td>\n",
       "      <td>7.598242e+03</td>\n",
       "      <td>461.458333</td>\n",
       "      <td>469.336667</td>\n",
       "      <td>0.129811</td>\n",
       "      <td>0.115940</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.007161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_attn.v_proj</th>\n",
       "      <td>3.682638e+03</td>\n",
       "      <td>3.043135e+03</td>\n",
       "      <td>96.638333</td>\n",
       "      <td>97.096667</td>\n",
       "      <td>0.056193</td>\n",
       "      <td>0.046435</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear1</th>\n",
       "      <td>6.408833e+01</td>\n",
       "      <td>6.145000e+01</td>\n",
       "      <td>489.408333</td>\n",
       "      <td>492.086667</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear2</th>\n",
       "      <td>7.866667e+00</td>\n",
       "      <td>7.858333e+00</td>\n",
       "      <td>2114.028333</td>\n",
       "      <td>2195.373333</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.004187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         error_gptq  error_gptq_one_shot  \\\n",
       "sub_part trans_part                                                        \n",
       "encoder  self_attn.attention_weights   7.167297e+04         6.224906e+04   \n",
       "         self_attn.output_proj         2.026401e+05         1.926753e+05   \n",
       "         self_attn.sampling_offsets    1.198736e+05         1.045355e+05   \n",
       "         self_attn.value_proj          2.993676e+05         2.589311e+05   \n",
       "         linear1                       1.907164e+06         1.755922e+06   \n",
       "         linear2                       1.087157e+05         1.126851e+05   \n",
       "decoder  cross_attn.attention_weights  2.978128e+03         2.716760e+03   \n",
       "         cross_attn.output_proj        5.137910e+03         5.186345e+03   \n",
       "         cross_attn.sampling_offsets   4.469888e+03         4.082293e+03   \n",
       "         cross_attn.value_proj         8.270184e+04         7.025100e+04   \n",
       "         self_attn.k_proj              7.563838e+03         6.667278e+03   \n",
       "         self_attn.out_proj            1.646522e+03         1.643693e+03   \n",
       "         self_attn.q_proj              8.507283e+03         7.598242e+03   \n",
       "         self_attn.v_proj              3.682638e+03         3.043135e+03   \n",
       "         linear1                       6.408833e+01         6.145000e+01   \n",
       "         linear2                       7.866667e+00         7.858333e+00   \n",
       "\n",
       "                                        error_ldlq  error_ldlq_one_shot  \\\n",
       "sub_part trans_part                                                       \n",
       "encoder  self_attn.attention_weights    381.266667           388.288333   \n",
       "         self_attn.output_proj          218.688333           213.981667   \n",
       "         self_attn.sampling_offsets     746.206667           758.101667   \n",
       "         self_attn.value_proj           211.565000           213.966667   \n",
       "         linear1                        755.916667           744.575000   \n",
       "         linear2                       1477.720000          1499.381667   \n",
       "decoder  cross_attn.attention_weights   564.711667           565.701667   \n",
       "         cross_attn.output_proj         241.780000           244.443333   \n",
       "         cross_attn.sampling_offsets    582.711667           571.501667   \n",
       "         cross_attn.value_proj           55.356667            56.888333   \n",
       "         self_attn.k_proj               668.545000           664.425000   \n",
       "         self_attn.out_proj             265.313333           260.726667   \n",
       "         self_attn.q_proj               461.458333           469.336667   \n",
       "         self_attn.v_proj                96.638333            97.096667   \n",
       "         linear1                        489.408333           492.086667   \n",
       "         linear2                       2114.028333          2195.373333   \n",
       "\n",
       "                                       normalized_error_gptq  \\\n",
       "sub_part trans_part                                            \n",
       "encoder  self_attn.attention_weights                2.187285   \n",
       "         self_attn.output_proj                      3.092043   \n",
       "         self_attn.sampling_offsets                 1.829126   \n",
       "         self_attn.value_proj                       4.567987   \n",
       "         linear1                                    3.637627   \n",
       "         linear2                                    0.207359   \n",
       "decoder  cross_attn.attention_weights               0.090885   \n",
       "         cross_attn.output_proj                     0.078398   \n",
       "         cross_attn.sampling_offsets                0.068205   \n",
       "         cross_attn.value_proj                      1.261930   \n",
       "         self_attn.k_proj                           0.115415   \n",
       "         self_attn.out_proj                         0.025124   \n",
       "         self_attn.q_proj                           0.129811   \n",
       "         self_attn.v_proj                           0.056193   \n",
       "         linear1                                    0.000122   \n",
       "         linear2                                    0.000015   \n",
       "\n",
       "                                       normalized_error_gptq_one_shot  \\\n",
       "sub_part trans_part                                                     \n",
       "encoder  self_attn.attention_weights                         1.899690   \n",
       "         self_attn.output_proj                               2.939992   \n",
       "         self_attn.sampling_offsets                          1.595086   \n",
       "         self_attn.value_proj                                3.950976   \n",
       "         linear1                                             3.349155   \n",
       "         linear2                                             0.214930   \n",
       "decoder  cross_attn.attention_weights                        0.082909   \n",
       "         cross_attn.output_proj                              0.079137   \n",
       "         cross_attn.sampling_offsets                         0.062291   \n",
       "         cross_attn.value_proj                               1.071945   \n",
       "         self_attn.k_proj                                    0.101735   \n",
       "         self_attn.out_proj                                  0.025081   \n",
       "         self_attn.q_proj                                    0.115940   \n",
       "         self_attn.v_proj                                    0.046435   \n",
       "         linear1                                             0.000117   \n",
       "         linear2                                             0.000015   \n",
       "\n",
       "                                       normalized_error_ldlq  \\\n",
       "sub_part trans_part                                            \n",
       "encoder  self_attn.attention_weights                0.011635   \n",
       "         self_attn.output_proj                      0.003337   \n",
       "         self_attn.sampling_offsets                 0.011386   \n",
       "         self_attn.value_proj                       0.003228   \n",
       "         linear1                                    0.001442   \n",
       "         linear2                                    0.002819   \n",
       "decoder  cross_attn.attention_weights               0.017234   \n",
       "         cross_attn.output_proj                     0.003689   \n",
       "         cross_attn.sampling_offsets                0.008891   \n",
       "         cross_attn.value_proj                      0.000845   \n",
       "         self_attn.k_proj                           0.010201   \n",
       "         self_attn.out_proj                         0.004048   \n",
       "         self_attn.q_proj                           0.007041   \n",
       "         self_attn.v_proj                           0.001475   \n",
       "         linear1                                    0.000933   \n",
       "         linear2                                    0.004032   \n",
       "\n",
       "                                       normalized_error_ldlq_one_shot  \n",
       "sub_part trans_part                                                    \n",
       "encoder  self_attn.attention_weights                         0.011850  \n",
       "         self_attn.output_proj                               0.003265  \n",
       "         self_attn.sampling_offsets                          0.011568  \n",
       "         self_attn.value_proj                                0.003265  \n",
       "         linear1                                             0.001420  \n",
       "         linear2                                             0.002860  \n",
       "decoder  cross_attn.attention_weights                        0.017264  \n",
       "         cross_attn.output_proj                              0.003730  \n",
       "         cross_attn.sampling_offsets                         0.008720  \n",
       "         cross_attn.value_proj                               0.000868  \n",
       "         self_attn.k_proj                                    0.010138  \n",
       "         self_attn.out_proj                                  0.003978  \n",
       "         self_attn.q_proj                                    0.007161  \n",
       "         self_attn.v_proj                                    0.001482  \n",
       "         linear1                                             0.000939  \n",
       "         linear2                                             0.004187  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[[\"sub_part\", \"trans_part\", \"error_gptq\", \"error_gptq_one_shot\", \"error_ldlq\", \"error_ldlq_one_shot\", \"normalized_error_gptq\", \"normalized_error_gptq_one_shot\", \"normalized_error_ldlq\", \"normalized_error_ldlq_one_shot\"]].groupby([\"sub_part\", \"trans_part\"]).mean().sort_index(key=lambda x: x.str[5:]).loc[[\"encoder\", \"decoder\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
