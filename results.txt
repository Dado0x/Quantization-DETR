Facebook - DETR

Test: Total time: 0:05:10 (0.1242 s / it)
Averaged stats: class_error: 14.29  loss: 1.0254 (1.1979)  loss_ce: 0.3283 (0.4904)  loss_bbox: 0.2005 (0.2247)  loss_giou: 0.4448 (0.4828)  loss_ce_unscaled: 0.3283 (0.4904)  class_error_unscaled: 17.8571 (22.0557)  loss_bbox_unscaled: 0.0401 (0.0449)  loss_giou_unscaled: 0.2224 (0.2414)  cardinality_error_unscaled: 4.0000 (5.0282)
Accumulating evaluation results...
DONE (t=9.02s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.624
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.311
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805


Base model Hugging Face - DETR

IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.624
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.311
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805

Transformer only:
    8bits

    DONE (t=7.88s).
    IoU metric: bbox
     Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420
     Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.624
     Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442
     Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205
     Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
     Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610
     Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333
     Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.533
     Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.574
     Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.311
     Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
     Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.804

    4bits

    DONE (t=8.13s).
    IoU metric: bbox
     Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403
     Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.615
     Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.421
     Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195
     Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439
     Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.601
     Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324
     Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.517
     Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559
     Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308
     Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.610
     Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797

Backbone + Transformer :

8bit
Accumulating evaluation results...
DONE (t=8.33s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.624
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.533
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.311
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805

Errors:
------------------
0_conv_encoder.model.embedder.embedder.convolution 108.5455322265625
0_conv_encoder.model.encoder.stages.0.layers.0.shortcut.convolution 3.662735939025879
0_conv_encoder.model.encoder.stages.0.layers.0.layer.0.convolution 1.5024539232254028
0_conv_encoder.model.encoder.stages.0.layers.0.layer.1.convolution 0.39641818404197693
0_conv_encoder.model.encoder.stages.0.layers.0.layer.2.convolution 0.3109032213687897
0_conv_encoder.model.encoder.stages.0.layers.1.layer.0.convolution 0.19584757089614868
0_conv_encoder.model.encoder.stages.0.layers.1.layer.1.convolution 0.4630991816520691
0_conv_encoder.model.encoder.stages.0.layers.1.layer.2.convolution 0.33886483311653137
0_conv_encoder.model.encoder.stages.0.layers.2.layer.0.convolution 0.23433277010917664
0_conv_encoder.model.encoder.stages.0.layers.2.layer.1.convolution 0.4782995879650116
0_conv_encoder.model.encoder.stages.0.layers.2.layer.2.convolution 0.34337347745895386
0_conv_encoder.model.encoder.stages.1.layers.0.shortcut.convolution 1.0670677423477173
0_conv_encoder.model.encoder.stages.1.layers.0.layer.0.convolution 1.6303586959838867
0_conv_encoder.model.encoder.stages.1.layers.0.layer.1.convolution 0.3165423572063446
0_conv_encoder.model.encoder.stages.1.layers.0.layer.2.convolution 0.40675193071365356
0_conv_encoder.model.encoder.stages.1.layers.1.layer.0.convolution 0.19693350791931152
0_conv_encoder.model.encoder.stages.1.layers.1.layer.1.convolution 0.17349731922149658
0_conv_encoder.model.encoder.stages.1.layers.1.layer.2.convolution 0.12407241016626358
0_conv_encoder.model.encoder.stages.1.layers.2.layer.0.convolution 0.41977936029434204
0_conv_encoder.model.encoder.stages.1.layers.2.layer.1.convolution 0.48463931679725647
0_conv_encoder.model.encoder.stages.1.layers.2.layer.2.convolution 0.26487675309181213
0_conv_encoder.model.encoder.stages.1.layers.3.layer.0.convolution 0.4739276170730591
0_conv_encoder.model.encoder.stages.1.layers.3.layer.1.convolution 0.3437950909137726
0_conv_encoder.model.encoder.stages.1.layers.3.layer.2.convolution 0.25354909896850586
0_conv_encoder.model.encoder.stages.2.layers.0.shortcut.convolution 0.5988374948501587
0_conv_encoder.model.encoder.stages.2.layers.0.layer.0.convolution 2.0037660598754883
0_conv_encoder.model.encoder.stages.2.layers.0.layer.1.convolution 0.28131794929504395
0_conv_encoder.model.encoder.stages.2.layers.0.layer.2.convolution 0.21787962317466736
0_conv_encoder.model.encoder.stages.2.layers.1.layer.0.convolution 0.1727445125579834
0_conv_encoder.model.encoder.stages.2.layers.1.layer.1.convolution 0.2355211079120636
0_conv_encoder.model.encoder.stages.2.layers.1.layer.2.convolution 0.1857997477054596
0_conv_encoder.model.encoder.stages.2.layers.2.layer.0.convolution 0.24313192069530487
0_conv_encoder.model.encoder.stages.2.layers.2.layer.1.convolution 0.13656246662139893
0_conv_encoder.model.encoder.stages.2.layers.2.layer.2.convolution 0.10953748226165771
0_conv_encoder.model.encoder.stages.2.layers.3.layer.0.convolution 0.2885284125804901
0_conv_encoder.model.encoder.stages.2.layers.3.layer.1.convolution 0.13150393962860107
0_conv_encoder.model.encoder.stages.2.layers.3.layer.2.convolution 0.09085424989461899
0_conv_encoder.model.encoder.stages.2.layers.4.layer.0.convolution 0.312747597694397
0_conv_encoder.model.encoder.stages.2.layers.4.layer.1.convolution 0.11939718574285507
0_conv_encoder.model.encoder.stages.2.layers.4.layer.2.convolution 0.0899030864238739
0_conv_encoder.model.encoder.stages.2.layers.5.layer.0.convolution 0.3174142837524414
0_conv_encoder.model.encoder.stages.2.layers.5.layer.1.convolution 0.14328733086585999
0_conv_encoder.model.encoder.stages.2.layers.5.layer.2.convolution 0.10610196739435196
0_conv_encoder.model.encoder.stages.3.layers.0.shortcut.convolution 0.19074022769927979
0_conv_encoder.model.encoder.stages.3.layers.0.layer.0.convolution 0.6219419240951538
0_conv_encoder.model.encoder.stages.3.layers.0.layer.1.convolution 0.07700586318969727
0_conv_encoder.model.encoder.stages.3.layers.0.layer.2.convolution 0.11560788005590439
0_conv_encoder.model.encoder.stages.3.layers.1.layer.0.convolution 0.9455208778381348
0_conv_encoder.model.encoder.stages.3.layers.1.layer.1.convolution 0.08228492736816406
0_conv_encoder.model.encoder.stages.3.layers.1.layer.2.convolution 0.08187055587768555
0_conv_encoder.model.encoder.stages.3.layers.2.layer.0.convolution 1.5913472175598145
0_conv_encoder.model.encoder.stages.3.layers.2.layer.1.convolution 0.03570013865828514
0_conv_encoder.model.encoder.stages.3.layers.2.layer.2.convolution 0.0431651845574379
1_ 6.365962028503418
2_self_attn.k_proj 7.1680097579956055
2_self_attn.v_proj 6.270335674285889
2_self_attn.q_proj 7.406434059143066
2_self_attn.out_proj 0.4229213297367096
2_fc1 51.43708801269531
2_fc2 1.6241151094436646
3_self_attn.k_proj 3.7467541694641113
3_self_attn.v_proj 1.8068253993988037
3_self_attn.q_proj 4.493406295776367
3_self_attn.out_proj 0.3227214217185974
3_fc1 44.443359375
3_fc2 1.7044787406921387
4_self_attn.k_proj 2.930356979370117
4_self_attn.v_proj 1.0401157140731812
4_self_attn.q_proj 2.5246477127075195
4_self_attn.out_proj 0.16816461086273193
4_fc1 36.62796401977539
4_fc2 2.428060531616211
5_self_attn.k_proj 6.455789566040039
5_self_attn.v_proj 0.9459185600280762
5_self_attn.q_proj 3.20684552192688
5_self_attn.out_proj 0.4005776643753052
5_fc1 27.111900329589844
5_fc2 3.5445022583007812
6_self_attn.k_proj 3.440608263015747
6_self_attn.v_proj 0.5427074432373047
6_self_attn.q_proj 4.011707305908203
6_self_attn.out_proj 0.17547255754470825
6_fc1 16.877933502197266
6_fc2 1.1887202262878418
7_self_attn.k_proj 1.2474684715270996
7_self_attn.v_proj 0.40640437602996826
7_self_attn.q_proj 3.3835296630859375
7_self_attn.out_proj 0.058801181614398956
7_fc1 7.021747589111328
7_fc2 0.2174738645553589
8_self_attn.k_proj 0.1420951783657074
8_self_attn.v_proj 0.0
8_self_attn.q_proj 0.17997141182422638
8_self_attn.out_proj 0.00010804986231960356
8_encoder_attn.k_proj 1.1448296308517456
8_encoder_attn.v_proj 0.8750357031822205
8_encoder_attn.q_proj 0.5607895851135254
8_encoder_attn.out_proj 0.3539101481437683
8_fc1 0.8084334135055542
8_fc2 0.08901490271091461
9_self_attn.k_proj 0.38302960991859436
9_self_attn.v_proj 0.028446178883314133
9_self_attn.q_proj 0.4369214177131653
9_self_attn.out_proj 0.015206903219223022
9_encoder_attn.k_proj 4.616654396057129
9_encoder_attn.v_proj 0.6466228365898132
9_encoder_attn.q_proj 1.888824462890625
9_encoder_attn.out_proj 0.15805292129516602
9_fc1 1.2987403869628906
9_fc2 0.07767482846975327
10_self_attn.k_proj 0.6135372519493103
10_self_attn.v_proj 0.060713328421115875
10_self_attn.q_proj 0.6817371249198914
10_self_attn.out_proj 0.012271590530872345
10_encoder_attn.k_proj 3.735274314880371
10_encoder_attn.v_proj 0.5519207715988159
10_encoder_attn.q_proj 2.883466958999634
10_encoder_attn.out_proj 0.0812002569437027
10_fc1 1.5512797832489014
10_fc2 0.07040910422801971
11_self_attn.k_proj 0.6323722004890442
11_self_attn.v_proj 0.07515653222799301
11_self_attn.q_proj 0.7487931847572327
11_self_attn.out_proj 0.006929717026650906
11_encoder_attn.k_proj 4.5257463455200195
11_encoder_attn.v_proj 0.45607292652130127
11_encoder_attn.q_proj 2.9285101890563965
11_encoder_attn.out_proj 0.036454178392887115
11_fc1 1.5632375478744507
11_fc2 0.040805622935295105
12_self_attn.k_proj 0.6441799998283386
12_self_attn.v_proj 0.05233517661690712
12_self_attn.q_proj 0.7031221389770508
12_self_attn.out_proj 0.002183875534683466
12_encoder_attn.k_proj 5.011960983276367
12_encoder_attn.v_proj 0.35116392374038696
12_encoder_attn.q_proj 3.2443008422851562
12_encoder_attn.out_proj 0.014900924637913704
12_fc1 1.3135548830032349
12_fc2 0.018023040145635605
13_self_attn.k_proj 0.4545724391937256
13_self_attn.v_proj 0.033452630043029785
13_self_attn.q_proj 0.4415627419948578
13_self_attn.out_proj 0.0003929072408936918
13_encoder_attn.k_proj 3.6408095359802246
13_encoder_attn.v_proj 0.2455361932516098
13_encoder_attn.q_proj 2.4360082149505615
13_encoder_attn.out_proj 0.005860998295247555
13_fc1 0.9644519686698914
13_fc2 0.005755503661930561
------------------
0_conv_encoder.model.embedder.embedder.convolution 108.5455322265625
2_fc1 51.43708801269531
3_fc1 44.443359375
4_fc1 36.62796401977539
5_fc1 27.111900329589844
6_fc1 16.877933502197266
2_self_attn.q_proj 7.406434059143066
2_self_attn.k_proj 7.1680097579956055
7_fc1 7.021747589111328
5_self_attn.k_proj 6.455789566040039
1_ 6.365962028503418
2_self_attn.v_proj 6.270335674285889
12_encoder_attn.k_proj 5.011960983276367
9_encoder_attn.k_proj 4.616654396057129
11_encoder_attn.k_proj 4.5257463455200195
3_self_attn.q_proj 4.493406295776367
6_self_attn.q_proj 4.011707305908203
3_self_attn.k_proj 3.7467541694641113
10_encoder_attn.k_proj 3.735274314880371
0_conv_encoder.model.encoder.stages.0.layers.0.shortcut.convolution 3.662735939025879
13_encoder_attn.k_proj 3.6408095359802246
5_fc2 3.5445022583007812
6_self_attn.k_proj 3.440608263015747
7_self_attn.q_proj 3.3835296630859375
12_encoder_attn.q_proj 3.2443008422851562
5_self_attn.q_proj 3.20684552192688
4_self_attn.k_proj 2.930356979370117
11_encoder_attn.q_proj 2.9285101890563965
10_encoder_attn.q_proj 2.883466958999634
4_self_attn.q_proj 2.5246477127075195
13_encoder_attn.q_proj 2.4360082149505615
4_fc2 2.428060531616211
0_conv_encoder.model.encoder.stages.2.layers.0.layer.0.convolution 2.0037660598754883
9_encoder_attn.q_proj 1.888824462890625
3_self_attn.v_proj 1.8068253993988037
3_fc2 1.7044787406921387
0_conv_encoder.model.encoder.stages.1.layers.0.layer.0.convolution 1.6303586959838867
2_fc2 1.6241151094436646
0_conv_encoder.model.encoder.stages.3.layers.2.layer.0.convolution 1.5913472175598145
11_fc1 1.5632375478744507
10_fc1 1.5512797832489014
0_conv_encoder.model.encoder.stages.0.layers.0.layer.0.convolution 1.5024539232254028
12_fc1 1.3135548830032349
9_fc1 1.2987403869628906
7_self_attn.k_proj 1.2474684715270996
6_fc2 1.1887202262878418
8_encoder_attn.k_proj 1.1448296308517456
0_conv_encoder.model.encoder.stages.1.layers.0.shortcut.convolution 1.0670677423477173
4_self_attn.v_proj 1.0401157140731812
13_fc1 0.9644519686698914
5_self_attn.v_proj 0.9459185600280762
0_conv_encoder.model.encoder.stages.3.layers.1.layer.0.convolution 0.9455208778381348
8_encoder_attn.v_proj 0.8750357031822205
8_fc1 0.8084334135055542
11_self_attn.q_proj 0.7487931847572327
12_self_attn.q_proj 0.7031221389770508
10_self_attn.q_proj 0.6817371249198914
9_encoder_attn.v_proj 0.6466228365898132
12_self_attn.k_proj 0.6441799998283386
11_self_attn.k_proj 0.6323722004890442
0_conv_encoder.model.encoder.stages.3.layers.0.layer.0.convolution 0.6219419240951538
10_self_attn.k_proj 0.6135372519493103
0_conv_encoder.model.encoder.stages.2.layers.0.shortcut.convolution 0.5988374948501587
8_encoder_attn.q_proj 0.5607895851135254
10_encoder_attn.v_proj 0.5519207715988159
6_self_attn.v_proj 0.5427074432373047
0_conv_encoder.model.encoder.stages.1.layers.2.layer.1.convolution 0.48463931679725647
0_conv_encoder.model.encoder.stages.0.layers.2.layer.1.convolution 0.4782995879650116
0_conv_encoder.model.encoder.stages.1.layers.3.layer.0.convolution 0.4739276170730591
0_conv_encoder.model.encoder.stages.0.layers.1.layer.1.convolution 0.4630991816520691
11_encoder_attn.v_proj 0.45607292652130127
13_self_attn.k_proj 0.4545724391937256
13_self_attn.q_proj 0.4415627419948578
9_self_attn.q_proj 0.4369214177131653
2_self_attn.out_proj 0.4229213297367096
0_conv_encoder.model.encoder.stages.1.layers.2.layer.0.convolution 0.41977936029434204
0_conv_encoder.model.encoder.stages.1.layers.0.layer.2.convolution 0.40675193071365356
7_self_attn.v_proj 0.40640437602996826
5_self_attn.out_proj 0.4005776643753052
0_conv_encoder.model.encoder.stages.0.layers.0.layer.1.convolution 0.39641818404197693
9_self_attn.k_proj 0.38302960991859436
8_encoder_attn.out_proj 0.3539101481437683
12_encoder_attn.v_proj 0.35116392374038696
0_conv_encoder.model.encoder.stages.1.layers.3.layer.1.convolution 0.3437950909137726
0_conv_encoder.model.encoder.stages.0.layers.2.layer.2.convolution 0.34337347745895386
0_conv_encoder.model.encoder.stages.0.layers.1.layer.2.convolution 0.33886483311653137
3_self_attn.out_proj 0.3227214217185974
0_conv_encoder.model.encoder.stages.2.layers.5.layer.0.convolution 0.3174142837524414
0_conv_encoder.model.encoder.stages.1.layers.0.layer.1.convolution 0.3165423572063446
0_conv_encoder.model.encoder.stages.2.layers.4.layer.0.convolution 0.312747597694397
0_conv_encoder.model.encoder.stages.0.layers.0.layer.2.convolution 0.3109032213687897
0_conv_encoder.model.encoder.stages.2.layers.3.layer.0.convolution 0.2885284125804901
0_conv_encoder.model.encoder.stages.2.layers.0.layer.1.convolution 0.28131794929504395
0_conv_encoder.model.encoder.stages.1.layers.2.layer.2.convolution 0.26487675309181213
0_conv_encoder.model.encoder.stages.1.layers.3.layer.2.convolution 0.25354909896850586
13_encoder_attn.v_proj 0.2455361932516098
0_conv_encoder.model.encoder.stages.2.layers.2.layer.0.convolution 0.24313192069530487
0_conv_encoder.model.encoder.stages.2.layers.1.layer.1.convolution 0.2355211079120636
0_conv_encoder.model.encoder.stages.0.layers.2.layer.0.convolution 0.23433277010917664
0_conv_encoder.model.encoder.stages.2.layers.0.layer.2.convolution 0.21787962317466736
7_fc2 0.2174738645553589
0_conv_encoder.model.encoder.stages.1.layers.1.layer.0.convolution 0.19693350791931152
0_conv_encoder.model.encoder.stages.0.layers.1.layer.0.convolution 0.19584757089614868
0_conv_encoder.model.encoder.stages.3.layers.0.shortcut.convolution 0.19074022769927979
0_conv_encoder.model.encoder.stages.2.layers.1.layer.2.convolution 0.1857997477054596
8_self_attn.q_proj 0.17997141182422638
6_self_attn.out_proj 0.17547255754470825
0_conv_encoder.model.encoder.stages.1.layers.1.layer.1.convolution 0.17349731922149658
0_conv_encoder.model.encoder.stages.2.layers.1.layer.0.convolution 0.1727445125579834
4_self_attn.out_proj 0.16816461086273193
9_encoder_attn.out_proj 0.15805292129516602
0_conv_encoder.model.encoder.stages.2.layers.5.layer.1.convolution 0.14328733086585999
8_self_attn.k_proj 0.1420951783657074
0_conv_encoder.model.encoder.stages.2.layers.2.layer.1.convolution 0.13656246662139893
0_conv_encoder.model.encoder.stages.2.layers.3.layer.1.convolution 0.13150393962860107
0_conv_encoder.model.encoder.stages.1.layers.1.layer.2.convolution 0.12407241016626358
0_conv_encoder.model.encoder.stages.2.layers.4.layer.1.convolution 0.11939718574285507
0_conv_encoder.model.encoder.stages.3.layers.0.layer.2.convolution 0.11560788005590439
0_conv_encoder.model.encoder.stages.2.layers.2.layer.2.convolution 0.10953748226165771
0_conv_encoder.model.encoder.stages.2.layers.5.layer.2.convolution 0.10610196739435196
0_conv_encoder.model.encoder.stages.2.layers.3.layer.2.convolution 0.09085424989461899
0_conv_encoder.model.encoder.stages.2.layers.4.layer.2.convolution 0.0899030864238739
8_fc2 0.08901490271091461
0_conv_encoder.model.encoder.stages.3.layers.1.layer.1.convolution 0.08228492736816406
0_conv_encoder.model.encoder.stages.3.layers.1.layer.2.convolution 0.08187055587768555
10_encoder_attn.out_proj 0.0812002569437027
9_fc2 0.07767482846975327
0_conv_encoder.model.encoder.stages.3.layers.0.layer.1.convolution 0.07700586318969727
11_self_attn.v_proj 0.07515653222799301
10_fc2 0.07040910422801971
10_self_attn.v_proj 0.060713328421115875
7_self_attn.out_proj 0.058801181614398956
12_self_attn.v_proj 0.05233517661690712
0_conv_encoder.model.encoder.stages.3.layers.2.layer.2.convolution 0.0431651845574379
11_fc2 0.040805622935295105
11_encoder_attn.out_proj 0.036454178392887115
0_conv_encoder.model.encoder.stages.3.layers.2.layer.1.convolution 0.03570013865828514
13_self_attn.v_proj 0.033452630043029785
9_self_attn.v_proj 0.028446178883314133
12_fc2 0.018023040145635605
9_self_attn.out_proj 0.015206903219223022
12_encoder_attn.out_proj 0.014900924637913704
10_self_attn.out_proj 0.012271590530872345
11_self_attn.out_proj 0.006929717026650906
13_encoder_attn.out_proj 0.005860998295247555
13_fc2 0.005755503661930561
12_self_attn.out_proj 0.002183875534683466
13_self_attn.out_proj 0.0003929072408936918
8_self_attn.out_proj 0.00010804986231960356
8_self_attn.v_proj 0.0
------------------

4bits

Accumulating evaluation results...
DONE (t=8.38s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.609
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.413
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.321
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.512
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.554
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.603
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786

Errors:
------------------
0_conv_encoder.model.embedder.embedder.convolution 30422.59765625
0_conv_encoder.model.encoder.stages.0.layers.0.shortcut.convolution 931.7242431640625
0_conv_encoder.model.encoder.stages.0.layers.0.layer.0.convolution 431.3337707519531
0_conv_encoder.model.encoder.stages.0.layers.0.layer.1.convolution 115.61201477050781
0_conv_encoder.model.encoder.stages.0.layers.0.layer.2.convolution 89.71524810791016
0_conv_encoder.model.encoder.stages.0.layers.1.layer.0.convolution 56.81736373901367
0_conv_encoder.model.encoder.stages.0.layers.1.layer.1.convolution 132.23358154296875
0_conv_encoder.model.encoder.stages.0.layers.1.layer.2.convolution 98.50074768066406
0_conv_encoder.model.encoder.stages.0.layers.2.layer.0.convolution 67.32398223876953
0_conv_encoder.model.encoder.stages.0.layers.2.layer.1.convolution 136.86647033691406
0_conv_encoder.model.encoder.stages.0.layers.2.layer.2.convolution 99.52357482910156
0_conv_encoder.model.encoder.stages.1.layers.0.shortcut.convolution 290.12860107421875
0_conv_encoder.model.encoder.stages.1.layers.0.layer.0.convolution 474.00457763671875
0_conv_encoder.model.encoder.stages.1.layers.0.layer.1.convolution 91.60176086425781
0_conv_encoder.model.encoder.stages.1.layers.0.layer.2.convolution 118.80550384521484
0_conv_encoder.model.encoder.stages.1.layers.1.layer.0.convolution 56.50432586669922
0_conv_encoder.model.encoder.stages.1.layers.1.layer.1.convolution 50.04048538208008
0_conv_encoder.model.encoder.stages.1.layers.1.layer.2.convolution 35.34355163574219
0_conv_encoder.model.encoder.stages.1.layers.2.layer.0.convolution 120.98568725585938
0_conv_encoder.model.encoder.stages.1.layers.2.layer.1.convolution 140.8129425048828
0_conv_encoder.model.encoder.stages.1.layers.2.layer.2.convolution 75.94863891601562
0_conv_encoder.model.encoder.stages.1.layers.3.layer.0.convolution 135.93771362304688
0_conv_encoder.model.encoder.stages.1.layers.3.layer.1.convolution 99.25455474853516
0_conv_encoder.model.encoder.stages.1.layers.3.layer.2.convolution 73.5848617553711
0_conv_encoder.model.encoder.stages.2.layers.0.shortcut.convolution 171.16671752929688
0_conv_encoder.model.encoder.stages.2.layers.0.layer.0.convolution 579.3160400390625
0_conv_encoder.model.encoder.stages.2.layers.0.layer.1.convolution 81.41806030273438
0_conv_encoder.model.encoder.stages.2.layers.0.layer.2.convolution 63.0434455871582
0_conv_encoder.model.encoder.stages.2.layers.1.layer.0.convolution 49.32343292236328
0_conv_encoder.model.encoder.stages.2.layers.1.layer.1.convolution 67.88661193847656
0_conv_encoder.model.encoder.stages.2.layers.1.layer.2.convolution 53.22802734375
0_conv_encoder.model.encoder.stages.2.layers.2.layer.0.convolution 70.06074523925781
0_conv_encoder.model.encoder.stages.2.layers.2.layer.1.convolution 39.56584930419922
0_conv_encoder.model.encoder.stages.2.layers.2.layer.2.convolution 31.391700744628906
0_conv_encoder.model.encoder.stages.2.layers.3.layer.0.convolution 83.21441650390625
0_conv_encoder.model.encoder.stages.2.layers.3.layer.1.convolution 38.00802993774414
0_conv_encoder.model.encoder.stages.2.layers.3.layer.2.convolution 26.059829711914062
0_conv_encoder.model.encoder.stages.2.layers.4.layer.0.convolution 90.66043090820312
0_conv_encoder.model.encoder.stages.2.layers.4.layer.1.convolution 34.454017639160156
0_conv_encoder.model.encoder.stages.2.layers.4.layer.2.convolution 25.859607696533203
0_conv_encoder.model.encoder.stages.2.layers.5.layer.0.convolution 91.68096923828125
0_conv_encoder.model.encoder.stages.2.layers.5.layer.1.convolution 41.62040710449219
0_conv_encoder.model.encoder.stages.2.layers.5.layer.2.convolution 30.74656105041504
0_conv_encoder.model.encoder.stages.3.layers.0.shortcut.convolution 52.16825866699219
0_conv_encoder.model.encoder.stages.3.layers.0.layer.0.convolution 179.42529296875
0_conv_encoder.model.encoder.stages.3.layers.0.layer.1.convolution 21.78429412841797
0_conv_encoder.model.encoder.stages.3.layers.0.layer.2.convolution 33.360172271728516
0_conv_encoder.model.encoder.stages.3.layers.1.layer.0.convolution 260.7757263183594
0_conv_encoder.model.encoder.stages.3.layers.1.layer.1.convolution 23.812023162841797
0_conv_encoder.model.encoder.stages.3.layers.1.layer.2.convolution 23.670068740844727
0_conv_encoder.model.encoder.stages.3.layers.2.layer.0.convolution 458.04290771484375
0_conv_encoder.model.encoder.stages.3.layers.2.layer.1.convolution 10.335002899169922
0_conv_encoder.model.encoder.stages.3.layers.2.layer.2.convolution 12.54065990447998
1_ 1808.86328125
2_self_attn.k_proj 2081.324951171875
2_self_attn.v_proj 1809.658203125
2_self_attn.q_proj 2149.83984375
2_self_attn.out_proj 122.01321411132812
2_fc1 14856.4140625
2_fc2 468.974609375
3_self_attn.k_proj 1078.1552734375
3_self_attn.v_proj 527.9359130859375
3_self_attn.q_proj 1305.17138671875
3_self_attn.out_proj 93.70314025878906
3_fc1 12868.5712890625
3_fc2 493.47979736328125
4_self_attn.k_proj 860.259521484375
4_self_attn.v_proj 305.3151550292969
4_self_attn.q_proj 739.9381103515625
4_self_attn.out_proj 48.94697189331055
4_fc1 10631.396484375
4_fc2 699.4611206054688
5_self_attn.k_proj 1876.7701416015625
5_self_attn.v_proj 277.02789306640625
5_self_attn.q_proj 933.7872314453125
5_self_attn.out_proj 116.94183349609375
5_fc1 7864.24169921875
5_fc2 1026.68408203125
6_self_attn.k_proj 994.102294921875
6_self_attn.v_proj 159.45632934570312
6_self_attn.q_proj 1175.211669921875
6_self_attn.out_proj 51.023834228515625
6_fc1 4930.6083984375
6_fc2 343.30462646484375
7_self_attn.k_proj 368.1783447265625
7_self_attn.v_proj 118.23523712158203
7_self_attn.q_proj 990.1259765625
7_self_attn.out_proj 16.957073211669922
7_fc1 2046.494384765625
7_fc2 62.747352600097656
8_self_attn.k_proj 40.996097564697266
8_self_attn.v_proj 0.0
8_self_attn.q_proj 53.030845642089844
8_self_attn.out_proj 0.03374849259853363
8_encoder_attn.k_proj 336.59637451171875
8_encoder_attn.v_proj 256.66790771484375
8_encoder_attn.q_proj 163.1481475830078
8_encoder_attn.out_proj 102.81179809570312
8_fc1 231.48858642578125
8_fc2 25.03752899169922
9_self_attn.k_proj 112.58659362792969
9_self_attn.v_proj 8.39111042022705
9_self_attn.q_proj 124.51760864257812
9_self_attn.out_proj 4.471858978271484
9_encoder_attn.k_proj 1313.94287109375
9_encoder_attn.v_proj 188.6597900390625
9_encoder_attn.q_proj 545.6918334960938
9_encoder_attn.out_proj 46.1133918762207
9_fc1 376.2322082519531
9_fc2 22.41223907470703
10_self_attn.k_proj 178.09059143066406
10_self_attn.v_proj 17.717491149902344
10_self_attn.q_proj 199.82598876953125
10_self_attn.out_proj 3.5829415321350098
10_encoder_attn.k_proj 1087.687744140625
10_encoder_attn.v_proj 162.96414184570312
10_encoder_attn.q_proj 830.262939453125
10_encoder_attn.out_proj 23.49873924255371
10_fc1 449.8913879394531
10_fc2 20.270586013793945
11_self_attn.k_proj 182.77926635742188
11_self_attn.v_proj 21.956253051757812
11_self_attn.q_proj 218.42807006835938
11_self_attn.out_proj 2.0335819721221924
11_encoder_attn.k_proj 1294.20458984375
11_encoder_attn.v_proj 133.69818115234375
11_encoder_attn.q_proj 859.6524047851562
11_encoder_attn.out_proj 10.599645614624023
11_fc1 456.8826904296875
11_fc2 11.793212890625
12_self_attn.k_proj 187.8923797607422
12_self_attn.v_proj 15.356938362121582
12_self_attn.q_proj 202.7965087890625
12_self_attn.out_proj 0.639712393283844
12_encoder_attn.k_proj 1434.275390625
12_encoder_attn.v_proj 101.58718872070312
12_encoder_attn.q_proj 946.5552978515625
12_encoder_attn.out_proj 4.33936882019043
12_fc1 385.677734375
12_fc2 5.18634033203125
13_self_attn.k_proj 132.54232788085938
13_self_attn.v_proj 9.796221733093262
13_self_attn.q_proj 128.50633239746094
13_self_attn.out_proj 0.1148548424243927
13_encoder_attn.k_proj 1018.8358764648438
13_encoder_attn.v_proj 71.99319458007812
13_encoder_attn.q_proj 709.6112060546875
13_encoder_attn.out_proj 1.709179401397705
13_fc1 281.37969970703125
13_fc2 1.6499691009521484
------------------
0_conv_encoder.model.embedder.embedder.convolution 30422.59765625
2_fc1 14856.4140625
3_fc1 12868.5712890625
4_fc1 10631.396484375
5_fc1 7864.24169921875
6_fc1 4930.6083984375
2_self_attn.q_proj 2149.83984375
2_self_attn.k_proj 2081.324951171875
7_fc1 2046.494384765625
5_self_attn.k_proj 1876.7701416015625
2_self_attn.v_proj 1809.658203125
1_ 1808.86328125
12_encoder_attn.k_proj 1434.275390625
9_encoder_attn.k_proj 1313.94287109375
3_self_attn.q_proj 1305.17138671875
11_encoder_attn.k_proj 1294.20458984375
6_self_attn.q_proj 1175.211669921875
10_encoder_attn.k_proj 1087.687744140625
3_self_attn.k_proj 1078.1552734375
5_fc2 1026.68408203125
13_encoder_attn.k_proj 1018.8358764648438
6_self_attn.k_proj 994.102294921875
7_self_attn.q_proj 990.1259765625
12_encoder_attn.q_proj 946.5552978515625
5_self_attn.q_proj 933.7872314453125
0_conv_encoder.model.encoder.stages.0.layers.0.shortcut.convolution 931.7242431640625
4_self_attn.k_proj 860.259521484375
11_encoder_attn.q_proj 859.6524047851562
10_encoder_attn.q_proj 830.262939453125
4_self_attn.q_proj 739.9381103515625
13_encoder_attn.q_proj 709.6112060546875
4_fc2 699.4611206054688
0_conv_encoder.model.encoder.stages.2.layers.0.layer.0.convolution 579.3160400390625
9_encoder_attn.q_proj 545.6918334960938
3_self_attn.v_proj 527.9359130859375
3_fc2 493.47979736328125
0_conv_encoder.model.encoder.stages.1.layers.0.layer.0.convolution 474.00457763671875
2_fc2 468.974609375
0_conv_encoder.model.encoder.stages.3.layers.2.layer.0.convolution 458.04290771484375
11_fc1 456.8826904296875
10_fc1 449.8913879394531
0_conv_encoder.model.encoder.stages.0.layers.0.layer.0.convolution 431.3337707519531
12_fc1 385.677734375
9_fc1 376.2322082519531
7_self_attn.k_proj 368.1783447265625
6_fc2 343.30462646484375
8_encoder_attn.k_proj 336.59637451171875
4_self_attn.v_proj 305.3151550292969
0_conv_encoder.model.encoder.stages.1.layers.0.shortcut.convolution 290.12860107421875
13_fc1 281.37969970703125
5_self_attn.v_proj 277.02789306640625
0_conv_encoder.model.encoder.stages.3.layers.1.layer.0.convolution 260.7757263183594
8_encoder_attn.v_proj 256.66790771484375
8_fc1 231.48858642578125
11_self_attn.q_proj 218.42807006835938
12_self_attn.q_proj 202.7965087890625
10_self_attn.q_proj 199.82598876953125
9_encoder_attn.v_proj 188.6597900390625
12_self_attn.k_proj 187.8923797607422
11_self_attn.k_proj 182.77926635742188
0_conv_encoder.model.encoder.stages.3.layers.0.layer.0.convolution 179.42529296875
10_self_attn.k_proj 178.09059143066406
0_conv_encoder.model.encoder.stages.2.layers.0.shortcut.convolution 171.16671752929688
8_encoder_attn.q_proj 163.1481475830078
10_encoder_attn.v_proj 162.96414184570312
6_self_attn.v_proj 159.45632934570312
0_conv_encoder.model.encoder.stages.1.layers.2.layer.1.convolution 140.8129425048828
0_conv_encoder.model.encoder.stages.0.layers.2.layer.1.convolution 136.86647033691406
0_conv_encoder.model.encoder.stages.1.layers.3.layer.0.convolution 135.93771362304688
11_encoder_attn.v_proj 133.69818115234375
13_self_attn.k_proj 132.54232788085938
0_conv_encoder.model.encoder.stages.0.layers.1.layer.1.convolution 132.23358154296875
13_self_attn.q_proj 128.50633239746094
9_self_attn.q_proj 124.51760864257812
2_self_attn.out_proj 122.01321411132812
0_conv_encoder.model.encoder.stages.1.layers.2.layer.0.convolution 120.98568725585938
0_conv_encoder.model.encoder.stages.1.layers.0.layer.2.convolution 118.80550384521484
7_self_attn.v_proj 118.23523712158203
5_self_attn.out_proj 116.94183349609375
0_conv_encoder.model.encoder.stages.0.layers.0.layer.1.convolution 115.61201477050781
9_self_attn.k_proj 112.58659362792969
8_encoder_attn.out_proj 102.81179809570312
12_encoder_attn.v_proj 101.58718872070312
0_conv_encoder.model.encoder.stages.0.layers.2.layer.2.convolution 99.52357482910156
0_conv_encoder.model.encoder.stages.1.layers.3.layer.1.convolution 99.25455474853516
0_conv_encoder.model.encoder.stages.0.layers.1.layer.2.convolution 98.50074768066406
3_self_attn.out_proj 93.70314025878906
0_conv_encoder.model.encoder.stages.2.layers.5.layer.0.convolution 91.68096923828125
0_conv_encoder.model.encoder.stages.1.layers.0.layer.1.convolution 91.60176086425781
0_conv_encoder.model.encoder.stages.2.layers.4.layer.0.convolution 90.66043090820312
0_conv_encoder.model.encoder.stages.0.layers.0.layer.2.convolution 89.71524810791016
0_conv_encoder.model.encoder.stages.2.layers.3.layer.0.convolution 83.21441650390625
0_conv_encoder.model.encoder.stages.2.layers.0.layer.1.convolution 81.41806030273438
0_conv_encoder.model.encoder.stages.1.layers.2.layer.2.convolution 75.94863891601562
0_conv_encoder.model.encoder.stages.1.layers.3.layer.2.convolution 73.5848617553711
13_encoder_attn.v_proj 71.99319458007812
0_conv_encoder.model.encoder.stages.2.layers.2.layer.0.convolution 70.06074523925781
0_conv_encoder.model.encoder.stages.2.layers.1.layer.1.convolution 67.88661193847656
0_conv_encoder.model.encoder.stages.0.layers.2.layer.0.convolution 67.32398223876953
0_conv_encoder.model.encoder.stages.2.layers.0.layer.2.convolution 63.0434455871582
7_fc2 62.747352600097656
0_conv_encoder.model.encoder.stages.0.layers.1.layer.0.convolution 56.81736373901367
0_conv_encoder.model.encoder.stages.1.layers.1.layer.0.convolution 56.50432586669922
0_conv_encoder.model.encoder.stages.2.layers.1.layer.2.convolution 53.22802734375
8_self_attn.q_proj 53.030845642089844
0_conv_encoder.model.encoder.stages.3.layers.0.shortcut.convolution 52.16825866699219
6_self_attn.out_proj 51.023834228515625
0_conv_encoder.model.encoder.stages.1.layers.1.layer.1.convolution 50.04048538208008
0_conv_encoder.model.encoder.stages.2.layers.1.layer.0.convolution 49.32343292236328
4_self_attn.out_proj 48.94697189331055
9_encoder_attn.out_proj 46.1133918762207
0_conv_encoder.model.encoder.stages.2.layers.5.layer.1.convolution 41.62040710449219
8_self_attn.k_proj 40.996097564697266
0_conv_encoder.model.encoder.stages.2.layers.2.layer.1.convolution 39.56584930419922
0_conv_encoder.model.encoder.stages.2.layers.3.layer.1.convolution 38.00802993774414
0_conv_encoder.model.encoder.stages.1.layers.1.layer.2.convolution 35.34355163574219
0_conv_encoder.model.encoder.stages.2.layers.4.layer.1.convolution 34.454017639160156
0_conv_encoder.model.encoder.stages.3.layers.0.layer.2.convolution 33.360172271728516
0_conv_encoder.model.encoder.stages.2.layers.2.layer.2.convolution 31.391700744628906
0_conv_encoder.model.encoder.stages.2.layers.5.layer.2.convolution 30.74656105041504
0_conv_encoder.model.encoder.stages.2.layers.3.layer.2.convolution 26.059829711914062
0_conv_encoder.model.encoder.stages.2.layers.4.layer.2.convolution 25.859607696533203
8_fc2 25.03752899169922
0_conv_encoder.model.encoder.stages.3.layers.1.layer.1.convolution 23.812023162841797
0_conv_encoder.model.encoder.stages.3.layers.1.layer.2.convolution 23.670068740844727
10_encoder_attn.out_proj 23.49873924255371
9_fc2 22.41223907470703
11_self_attn.v_proj 21.956253051757812
0_conv_encoder.model.encoder.stages.3.layers.0.layer.1.convolution 21.78429412841797
10_fc2 20.270586013793945
10_self_attn.v_proj 17.717491149902344
7_self_attn.out_proj 16.957073211669922
12_self_attn.v_proj 15.356938362121582
0_conv_encoder.model.encoder.stages.3.layers.2.layer.2.convolution 12.54065990447998
11_fc2 11.793212890625
11_encoder_attn.out_proj 10.599645614624023
0_conv_encoder.model.encoder.stages.3.layers.2.layer.1.convolution 10.335002899169922
13_self_attn.v_proj 9.796221733093262
9_self_attn.v_proj 8.39111042022705
12_fc2 5.18634033203125
9_self_attn.out_proj 4.471858978271484
12_encoder_attn.out_proj 4.33936882019043
10_self_attn.out_proj 3.5829415321350098
11_self_attn.out_proj 2.0335819721221924
13_encoder_attn.out_proj 1.709179401397705
13_fc2 1.6499691009521484
12_self_attn.out_proj 0.639712393283844
13_self_attn.out_proj 0.1148548424243927
8_self_attn.out_proj 0.03374849259853363
8_self_attn.v_proj 0.0
------------------

